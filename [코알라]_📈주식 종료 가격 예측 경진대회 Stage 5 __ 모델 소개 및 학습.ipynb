{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": " [ì½”ì•Œë¼] ì£¼ì‹ ì¢…ë£Œ ê°€ê²© ì˜ˆì¸¡ ê²½ì§„ëŒ€íšŒ Stage 5 : ëª¨ë¸ ì†Œê°œ ë° í•™ìŠµ\n\nì•ˆë…•í•˜ì„¸ìš”. ë°ì´í¬ë£¨ 4ê¸° ì½”ì•Œë¼ğŸ¨ íŒ€ì…ë‹ˆë‹¤. \n\nì €í¬ëŠ” ğŸ“ˆì£¼ì‹ ì¢…ë£Œ ê°€ê²© ì˜ˆì¸¡ ê²½ì§„ëŒ€íšŒë¥¼ ì£¼ì œë¡œ PBLë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n\nì´ë²ˆ í™œë™ì„ í†µí•´ ë…¼ë¦¬ì ì¸ ì ‘ê·¼ ë°©ì‹ìœ¼ë¡œ ëª¨ë“  ë¬¸ì œë¥¼ í’€ì–´ê°ˆ ìˆ˜ ìˆëŠ” ë°ì´ì»¤ê°€ ë˜ëŠ” ê²ƒì„ ìµœì¢… ëª©í‘œë¡œ í•˜ê³  ìˆìŠµë‹ˆë‹¤. \n\nStage 5ì€ PBLì„ êµ¬ì„±í•˜ëŠ” 6ê°€ì§€ ë‹¨ê³„ ì¤‘ 5ë²ˆì§¸ ë‹¨ê³„ë¡œì„œ ëª¨ë¸ ì†Œê°œ ë° í•™ìŠµ ë‚´ìš©ì„ ë‹´ê³ ìˆìŠµë‹ˆë‹¤.\n\në‹¤ìŒì˜ í¬ìŠ¤íŒ…ì€ ë°ì´í¬ë£¨ 4ê¸° í™œë™ìœ¼ë¡œ ì¸í•˜ì—¬ ì‘ì„±ë˜ì—ˆìŒì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Stage 5.\n# 1. Review\n\nStage 5ì˜ ì½”ë“œë¥¼ ì •ìƒì ìœ¼ë¡œ ì‹¤í–‰í•˜ê¸° ìœ„í•´ì„œëŠ”, ì•ì„œ Stage 4ì—ì„œ ì§„í–‰í–ˆë˜ ì½”ë“œë¥¼ ì „ë¶€ ì‹¤í–‰í•œ ìƒíƒœì—¬ì•¼ í•©ë‹ˆë‹¤.\n\në’¤ì—ì„œ ì‚¬ìš©í•  ê¸°ë³¸ ì„¤ì •ì„ ìœ„í•´ ì €í¬ê°€ ì¶”ê°€ì ì¸ ì½”ë“œì™€ í•¨ê»˜ í•œë²ˆì— ì¤€ë¹„í–ˆìœ¼ë‹ˆ, ì´ ì½”ë“œì°½ì„ ì‹¤í–‰ì‹œí‚¤ê³  ë“¤ì–´ê°€ì£¼ì„¸ìš”!\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import micropip\nawait micropip.install('requests')",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nimport datetime\nimport requests as req\nimport lightgbm as lgb\nfrom sklearn import linear_model\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.feature_selection import SelectKBest, f_regression, f_classif\nfrom sklearn import metrics\nimport os\nimport sys\nimport random\nimport warnings",
      "metadata": {
        "trusted": true
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "warnings.filterwarnings(action='ignore')\nos.chdir('./practice_data')",
      "metadata": {
        "trusted": true
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "## ê³¼ê±° ìƒì¥íì§€ì¢…ëª© ì¶”ì¶œ \ndf_out_tt1 = pd.read_csv('ì½”ìŠ¤í”¼ìƒíí˜„í™©.csv', encoding='utf-8')\ndf_out_tt2 = pd.read_csv('ì½”ìŠ¤ë‹¥ìƒíí˜„í™©.csv', encoding='utf-8')\n\ndf_out_tt1['Market'] = 'KOSPI'\ndf_out_tt2['Market'] = 'KOSDAQ'\ndf_out_tt = pd.concat([df_out_tt1, df_out_tt2])\ndf_out_tt.rename(columns = {\"ì¢…ëª©ì½”ë“œ\":\"code\", \"íšŒì‚¬ëª…\":\"code_nm\", \"íì§€ì¼ì\":\"out_dt\", \"íì§€ì‚¬ìœ \":\"out_desc\", \"Market\":'market'}, inplace = True)\ndf_out_tt['code'] = df_out_tt['code'].astype(str) \ndf_out_tt['code'] = df_out_tt['code'].str.zfill(6) \ndf_out_tt['out_dt'] = pd.to_datetime(df_out_tt['out_dt'])\ndf_out_tt = df_out_tt[[\"code\", \"code_nm\", \"out_dt\", \"out_desc\", \"market\"]]\n\n## í˜„ì¬ ìƒì¥ì¢…ëª© ì „ì²´ ì¶”ì¶œ : FinanceDataReader\ndf_in_tt = pd.read_csv('ì¢…ëª©ë¦¬ìŠ¤íŠ¸.csv', encoding='utf-8-sig')\ndf_in_tt.columns = ['code', 'isu_cd', 'code_nm', 'market', 'dept', 'close', 'changecode', 'changes', 'chagesratio', \n                    'open', 'high', 'low', 'volume', 'amount', 'marcap', 'stocks', 'marketId']\ndf_in_tt = df_in_tt[(df_in_tt['market'] !='KONEX') &                \n                    (df_in_tt.code.str.startswith('5') != True) &   \n                    (df_in_tt.code.str.startswith('6') != True) &   \n                    (df_in_tt.code.str.startswith('7') != True) &   \n                    (df_in_tt.code.str.len() == 6)]\ndf_in_tt['in_yn'] = 1  \ndf_in_tt['code'] = df_in_tt['code'].astype(str) \ndf_in_tt['code'] = df_in_tt['code'].str.zfill(6) \ndf_in_tt['close'] = df_in_tt['close'].astype(str)\ndf_in_tt['changecode'] = df_in_tt['close'].astype(str)\n\n## ê³¼ê±° ìƒì¥íì§€ì¢…ëª© + í˜„ì¬ ìƒì¥ì¢…ëª© ê²°í•©\nend_dt = datetime.datetime.now().strftime('%Y%m%d')   \ndf_stock_code = pd.merge(df_out_tt, df_in_tt, how='outer', on='code', suffixes=('_old', '_new'))\ndf_stock_code['in_yn'] = np.where(df_stock_code['in_yn'].notnull(), df_stock_code['in_yn'], 0)\ndf_stock_code['market'] = np.where(df_stock_code['market_new'].notnull(), df_stock_code['market_new'], df_stock_code['market_old'])\ndf_stock_code['code_nm'] = np.where(df_stock_code['code_nm_new'].notnull(), df_stock_code['code_nm_new'], df_stock_code['code_nm_old'])\ndf_stock_code['base_dt'] = pd.to_datetime(end_dt)\ndf_stock_code.rename(columns = {\"ListingDate\":\"in_dt\"}, inplace = True) \ndf_stock_code = df_stock_code.sort_values(by=['code', 'base_dt'], axis=0, ascending=[True, False])  \ndf_stock_code = df_stock_code.drop_duplicates(['code'], keep='first')\ndf_stock_code = df_stock_code[['code','code_nm','in_yn','market','out_dt','out_desc','base_dt']]\ndf_stock_code = df_stock_code[df_stock_code['code']=='005930']\n\ndf_price = pd.read_csv('ì£¼ê°€íŒŒì¼.csv', encoding='utf-8')\ndf_price['dt'] = pd.to_datetime(df_price['dt'])\ndf_price['dt_base'] = pd.to_datetime(df_price['dt_base'])\ndf_price['code'] = df_price['code'].astype(str)\ndf_price['code'] = df_price['code'].str.zfill(6)\n\ndf_usdkrw = pd.read_csv('í™˜ìœ¨íŒŒì¼.csv', encoding='utf-8')    \ndf_index = pd.read_csv('ì£¼ê°€ì§€ìˆ˜.csv', encoding='utf-8')\ndf_index['dt'] = pd.to_datetime(df_index['dt'])\ndf_usdkrw['dt'] = pd.to_datetime(df_usdkrw['dt'])\n\n## í•™ìŠµ ëŒ€ìƒ ì¢…ëª© ì„ ì • \nstock_list = pd.read_csv(\"./stock_list.csv\")\nstock_list['ì¢…ëª©ì½”ë“œ'] = stock_list['ì¢…ëª©ì½”ë“œ'].apply(lambda x : str(x).zfill(6))\nstock_list.rename(columns = {\"ì¢…ëª©ì½”ë“œ\":\"code\"}, inplace = True) \n\ndf_master = df_price[(df_price['open'] > 0) & (df_price['end'] > 0) & (df_price['cnt'] > 0)]\ndf_master['amt']  = df_master['end'] * df_master['cnt']   \ndf_amt = df_master.groupby(['code'], as_index=False)[['end', 'cnt', 'amt']].mean()\ndf_amt = df_amt[(df_amt['end'] >= 3000) & (df_amt['amt'] >= 2000000000)]     \ndl_amt = df_amt['code'].values.tolist() \ndl_200 = stock_list['code'].values.tolist() \ndl_amt = set(dl_amt + dl_200)\ndf_master = df_master[df_master['code'].isin(dl_amt)]\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "## Target ìƒì„±\ndf_master = df_master.sort_values(by=['code', 'dt'], axis=0, ascending=[True, False])  \ndf_master['num'] = df_master.groupby('code')['dt'].rank(ascending=True).astype(int)\ndf_master['y_01d_yn']  = np.where(df_master['code'] == df_master['code'].shift(1), 1, 0)  \ndf_master['y_02d_yn']  = np.where(df_master['code'] == df_master['code'].shift(2), 1, 0)  \ndf_master['y_03d_yn']  = np.where(df_master['code'] == df_master['code'].shift(3), 1, 0)  \ndf_master['y_04d_yn']  = np.where(df_master['code'] == df_master['code'].shift(4), 1, 0)  \ndf_master['y_05d_yn']  = np.where(df_master['code'] == df_master['code'].shift(5), 1, 0)  \ndf_master['y_rt_01d_eeup']  = df_master['end'].shift(1) / df_master['end']\ndf_master['y_rt_02d_eeup']  = df_master['end'].shift(2) / df_master['end']\ndf_master['y_rt_03d_eeup']  = df_master['end'].shift(3) / df_master['end']\ndf_master['y_rt_04d_eeup']  = df_master['end'].shift(4) / df_master['end']\ndf_master['y_rt_05d_eeup']  = df_master['end'].shift(5) / df_master['end']\n\ndf_master = df_master.sort_values(by=['code', 'dt'], axis=0) \ndf_master = pd.merge(df_master, df_index[['dt', 'end_kpi', 'end_ksd']], how='left', on='dt')\ndf_master = pd.merge(df_master, df_stock_code[['code', 'market']], how='left', on='code')\ndf_master['x_rt_end_index']  = np.where(df_master['market'] == 'KOSPI', df_master['end'] / df_master['end_kpi'], \n                                        df_master['end'] / df_master['end_ksd'])\ndf_master = pd.merge(df_master, df_usdkrw[['dt', 'end_usdkrw']], how='left', on='dt')\ndf_master['x_rt_end_usdkrw'] = df_master['end'] / df_master['end_usdkrw']\n\n## ì‹œ/ì €/ê³ /ì € íŒŒìƒ\ndf_master['avg_amt_20'] = df_master['amt'].rolling(window=20).mean() \ndf_master['x_rt_h_l']  = np.where(df_master['low'] == 0,  np.nan, df_master['high'] / df_master['low'])      \ndf_master['x_rt_e_s']  = np.where(df_master['open'] == 0,  np.nan, df_master['end'] / df_master['open'])   \ndf_master['x_rt_e_l']  = np.where(df_master['low'] == 0,  np.nan, df_master['end'] / df_master['low']) \ndf_master['x_rt_h_s']  = np.where(df_master['open'] == 0,  np.nan, df_master['high'] / df_master['open'])   \ndf_master['x_rt_s_l']  = np.where(df_master['low'] == 0,  np.nan, df_master['open'] / df_master['low'])  \ndf_master['x_rt_bf_1']  = np.where(df_master['end'].shift(1) == 0,   np.nan, df_master['end'] / df_master['end'].shift(1))\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "## ê³¼ê±° í‰ê·  ëŒ€ë¹„ ì´ê²©ë„ Feature \nk  = 3; k2 = 10; k3 = 40; k4 = 80\n\ndl_num_cols = ['open', 'high', 'low', 'end', 'amt', 'end_kpi', 'end_ksd', 'x_rt_end_index',\n               'x_rt_bf_1', 'x_rt_e_s', 'x_rt_e_l', 'end_usdkrw', 'x_rt_end_usdkrw' ] \n\ndl_cols =[('x_rt_bf_1_' + w) for w in dl_num_cols]\ndf_master[dl_cols]  = np.where(df_master[dl_num_cols].shift(1) == 0,  np.nan, df_master[dl_num_cols] / df_master[dl_num_cols].shift(1))\n\ndl_cols =[('x_rt_ma_k_' + w) for w in dl_num_cols]\ndf_master[dl_cols]  = np.where(df_master[dl_num_cols].rolling(window=k).mean() == 0,  np.nan, \n                      (df_master[dl_num_cols]-df_master[dl_num_cols].rolling(window=k).mean()) / df_master[dl_num_cols].rolling(window=k2).mean())  \ndf_master[dl_cols] = np.where(df_master[dl_num_cols] >= df_master[dl_num_cols].rolling(window=k).mean(), \n                      abs(df_master[dl_cols]), -abs(df_master[dl_cols]))                                                \n                        \ndl_cols =[('x_rt_ma_k2_' + w) for w in dl_num_cols]\ndf_master[dl_cols]  = np.where(df_master[dl_num_cols].rolling(window=k2).mean() == 0,  np.nan, \n                      (df_master[dl_num_cols]-df_master[dl_num_cols].rolling(window=k2).mean()) / df_master[dl_num_cols].rolling(window=k2).mean())  \ndf_master[dl_cols] = np.where(df_master[dl_num_cols] >= df_master[dl_num_cols].rolling(window=k2).mean(), \n                      abs(df_master[dl_cols]), -abs(df_master[dl_cols]))\n                        \ndl_cols =[('x_rt_ma_k_k2_' + w) for w in dl_num_cols]\ndf_master[dl_cols]  = np.where(df_master[dl_num_cols].rolling(window=k2).mean() == 0,  np.nan, \n                      (df_master[dl_num_cols].rolling(window=k).mean()-df_master[dl_num_cols].rolling(window=k2).mean()) / df_master[dl_num_cols].rolling(window=k2).mean())  \ndf_master[dl_cols] = np.where(df_master[dl_num_cols].rolling(window=k).mean() >= df_master[dl_num_cols].rolling(window=k2).mean(), \n                      abs(df_master[dl_cols]), -abs(df_master[dl_cols]))\n\ndl_cols =[('x_rt_ma_k3_' + w) for w in dl_num_cols]\ndf_master[dl_cols]  = np.where(df_master[dl_num_cols].rolling(window=k3).mean() == 0,  np.nan, \n\t\t\t\t\t\t\t (df_master[dl_num_cols]-df_master[dl_num_cols].rolling(window=k3).mean()) / df_master[dl_num_cols].rolling(window=k2).mean())  \ndf_master[dl_cols] = np.where(df_master[dl_num_cols] >= df_master[dl_num_cols].rolling(window=k3).mean(), \n\t\t\t\t\t\t\t abs(df_master[dl_cols]), -abs(df_master[dl_cols]))\n\t\t\t\t\t\t\t \ndl_cols =[('x_rt_ma_k_k3_' + w) for w in dl_num_cols]\ndf_master[dl_cols]  = np.where(df_master[dl_num_cols].rolling(window=k3).mean() == 0,  np.nan, \n\t\t\t\t\t\t\t (df_master[dl_num_cols].rolling(window=k).mean()-df_master[dl_num_cols].rolling(window=k3).mean()) / df_master[dl_num_cols].rolling(window=k2).mean())  \ndf_master[dl_cols] = np.where(df_master[dl_num_cols].rolling(window=k).mean() >= df_master[dl_num_cols].rolling(window=k3).mean(), \n\t\t\t\t\t\t\t abs(df_master[dl_cols]), -abs(df_master[dl_cols]))\n\t\t\t\t\t\t\t \ndl_cols =[('x_rt_ma_k2_k3_' + w) for w in dl_num_cols]\ndf_master[dl_cols]  = np.where(df_master[dl_num_cols].rolling(window=k3).mean() == 0,  np.nan, \n\t\t\t\t\t\t\t (df_master[dl_num_cols].rolling(window=k2).mean()-df_master[dl_num_cols].rolling(window=k3).mean()) / df_master[dl_num_cols].rolling(window=k2).mean())  \ndf_master[dl_cols] = np.where(df_master[dl_num_cols].rolling(window=k2).mean() >= df_master[dl_num_cols].rolling(window=k3).mean(), \n\t\t\t\t\t\t\t abs(df_master[dl_cols]), -abs(df_master[dl_cols]))\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t \ndl_cols =[('x_rt_ma_k4_' + w) for w in dl_num_cols]\ndf_master[dl_cols]  = np.where(df_master[dl_num_cols].rolling(window=k4).mean() == 0,  np.nan, \n\t\t\t\t\t\t\t (df_master[dl_num_cols]-df_master[dl_num_cols].rolling(window=k4).mean()) / df_master[dl_num_cols].rolling(window=k2).mean())  \ndf_master[dl_cols] = np.where(df_master[dl_num_cols] >= df_master[dl_num_cols].rolling(window=k4).mean(), \n\t\t\t\t\t\t\t abs(df_master[dl_cols]), -abs(df_master[dl_cols]))\n\t\t\t\t\t\t\t \ndl_cols =[('x_rt_ma_k_k4_' + w) for w in dl_num_cols]\ndf_master[dl_cols]  = np.where(df_master[dl_num_cols].rolling(window=k4).mean() == 0,  np.nan, \n\t\t\t\t\t\t\t (df_master[dl_num_cols].rolling(window=k).mean()-df_master[dl_num_cols].rolling(window=k4).mean()) / df_master[dl_num_cols].rolling(window=k2).mean())  \ndf_master[dl_cols] = np.where(df_master[dl_num_cols].rolling(window=k).mean() >= df_master[dl_num_cols].rolling(window=k4).mean(), \n\t\t\t\t\t\t\t abs(df_master[dl_cols]), -abs(df_master[dl_cols]))\n\t\t\t\t\t\t\t \ndl_cols =[('x_rt_ma_k2_k4_' + w) for w in dl_num_cols]\ndf_master[dl_cols]  = np.where(df_master[dl_num_cols].rolling(window=k4).mean() == 0,  np.nan, \n\t\t\t\t\t\t\t (df_master[dl_num_cols].rolling(window=k2).mean()-df_master[dl_num_cols].rolling(window=k4).mean()) / df_master[dl_num_cols].rolling(window=k2).mean())  \ndf_master[dl_cols] = np.where(df_master[dl_num_cols].rolling(window=k2).mean() >= df_master[dl_num_cols].rolling(window=k4).mean(), \n\t\t\t\t\t\t\t abs(df_master[dl_cols]), -abs(df_master[dl_cols]))\n\t\t\t\t\t\t\t \ndl_cols =[('x_rt_ma_k3_k4_' + w) for w in dl_num_cols]\ndf_master[dl_cols]  = np.where(df_master[dl_num_cols].rolling(window=k4).mean() == 0,  np.nan, \n\t\t\t\t\t\t\t (df_master[dl_num_cols].rolling(window=k3).mean()-df_master[dl_num_cols].rolling(window=k4).mean()) / df_master[dl_num_cols].rolling(window=k2).mean())  \ndf_master[dl_cols] = np.where(df_master[dl_num_cols].rolling(window=k3).mean() >= df_master[dl_num_cols].rolling(window=k4).mean(), \n\t\t\t\t\t\t\t abs(df_master[dl_cols]), -abs(df_master[dl_cols]))\n\n## ë‹¨ìˆœì´ë™í‰ê·  ëŒ€ë¹„ ì§€ìˆ˜ì´ë™í‰ê·  ëŒ€ë¹„ ì´ê²©ë„\nfor col in dl_num_cols:\n\tstr_ma05 = 'ma05_' + col\n\tstr_ema05 = 'ema05_' + col\n\tstr_rt_ema05_ma05 = 'x_rt_ema05_ma05_' + col\n\tdf_master[str_ma05] = df_master[col].rolling(window=5).mean() \t\t\n\tdf_master[str_ema05]  = df_master[col].shift(5) \n\ttmp1 = 0.7 \t\n\tfor i in range(5):\n\t\tdf_master[str_ema05]  = (df_master[col].shift(5-1-i) * tmp1) + (df_master[str_ema05] * (1-tmp1))\t\t\n\tdf_master[str_rt_ema05_ma05] = np.where(df_master[str_ma05] == 0,  np.nan, (df_master[str_ema05]-df_master[str_ma05]) / df_master[str_ma05])  \n\tdf_master[str_rt_ema05_ma05] = np.where(df_master[str_ema05] >= df_master[str_ma05], abs(df_master[str_rt_ema05_ma05]), -abs(df_master[str_rt_ema05_ma05]))\t\t   \n\n\tstr_ma20 = 'ma20_' + col\n\tstr_ema20 = 'ema20_' + col\n\tstr_rt_ema20_ma20 = 'x_rt_ema20_ma20_' + col\n\tdf_master[str_ma20] = df_master[col].rolling(window=20).mean() \t\t\n\tdf_master[str_ema20]  = df_master[col].shift(20) \n\ttmp1 = 0.7 \t\n\tfor i in range(20):\n\t\tdf_master[str_ema20]  = (df_master[col].shift(20-1-i) * tmp1) + (df_master[str_ema20] * (1-tmp1))\t\t\n\tdf_master[str_rt_ema20_ma20] = np.where(df_master[str_ma20] == 0,  np.nan, (df_master[str_ema20]-df_master[str_ma20]) / df_master[str_ma20])  \n\tdf_master[str_rt_ema20_ma20] = np.where(df_master[str_ema20] >= df_master[str_ma20], abs(df_master[str_rt_ema20_ma20]), -abs(df_master[str_rt_ema20_ma20]))\t\t   \n\n\tstr_ma40 = 'ma40_' + col\n\tstr_ema40 = 'ema40_' + col\n\tstr_rt_ema40_ma40 = 'x_rt_ema40_ma40_' + col\n\tdf_master[str_ma40] = df_master[col].rolling(window=40).mean() \t\t\n\tdf_master[str_ema40]  = df_master[col].shift(40) \n\ttmp1 = 0.7 \t\n\tfor i in range(40):\n\t\tdf_master[str_ema40]  = (df_master[col].shift(40-1-i) * tmp1) + (df_master[str_ema40] * (1-tmp1))\t\t\n\tdf_master[str_rt_ema40_ma40] = np.where(df_master[str_ma40] == 0,  np.nan, (df_master[str_ema40]-df_master[str_ma40]) / df_master[str_ma40])  \n\tdf_master[str_rt_ema40_ma40] = np.where(df_master[str_ema40] >= df_master[str_ma40], abs(df_master[str_rt_ema40_ma40]), -abs(df_master[str_rt_ema40_ma40]))\t\t   \n\n\tstr_ma80 = 'ma80_' + col\n\tstr_ema80 = 'ema80_' + col\n\tstr_rt_ema80_ma80 = 'x_rt_ema80_ma80_' + col\n\tdf_master[str_ma80] = df_master[col].rolling(window=80).mean() \t\t\n\tdf_master[str_ema80]  = df_master[col].shift(80) \n\ttmp1 = 0.7 \t\n\tfor i in range(80):\n\t\tdf_master[str_ema80]  = (df_master[col].shift(80-1-i) * tmp1) + (df_master[str_ema80] * (1-tmp1))\t\t\n\tdf_master[str_rt_ema80_ma80] = np.where(df_master[str_ma80] == 0,  np.nan, (df_master[str_ema80]-df_master[str_ma80]) / df_master[str_ma80])  \n\tdf_master[str_rt_ema80_ma80] = np.where(df_master[str_ema80] >= df_master[str_ma80], abs(df_master[str_rt_ema80_ma80]), -abs(df_master[str_rt_ema80_ma80]))\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "## Lag ë³€ìˆ˜\t\t\ndl_code = ['x_rt_bf_1', 'x_rt_h_l', 'x_rt_e_s', 'x_rt_e_l']\nfor m in range(10):   \n\tfor code in dl_code:\n\t\tstr_x = 'x_lag_' + code + str(m+1) \t\n\t\tdf_master[str_x] = df_master[code].shift(m+1)\n\t\n\n## NVI(Negative Volume Index)\n\n# end + cnt\t\ndf_master['x_ind_nvi_10'] = 100\ndf_master['cnt_tmp'] = df_master['cnt'].shift(10)\ndf_master['end_tmp'] = df_master['end'].shift(10) \nfor i in range(9, -1, -1):  \n\tdf_master['tmp1'] = np.where(df_master['end_tmp'] == 0, np.nan, \n\t\t\t\t\t\t\t\t   ((df_master['end'].shift(i) - df_master['end_tmp']) / df_master['end_tmp']) * 100)\n\tdf_master['x_ind_nvi_10'] = np.where(df_master['cnt'].shift(i) < df_master['cnt_tmp'], df_master['x_ind_nvi_10'] + df_master['tmp1'], \n\t\t\t\t\t\t\t\t\t\tdf_master['x_ind_nvi_10'])\n\tdf_master['cnt_tmp'] = df_master['cnt'].shift(i)\n\tdf_master['end_tmp'] = df_master['end'].shift(i)\n\t\n# high + cnt\t\ndf_master['x_ind_h_nvi_10'] = 100\ndf_master['cnt_tmp'] = df_master['cnt'].shift(10)\ndf_master['high_tmp'] = df_master['high'].shift(10) \nfor i in range(9, -1, -1):  \n\tdf_master['tmp1'] = np.where(df_master['high_tmp'] == 0, np.nan, \n\t\t\t\t\t\t\t\t   ((df_master['high'].shift(i) - df_master['high_tmp']) / df_master['high_tmp']) * 100)\n\tdf_master['x_ind_h_nvi_10'] = np.where(df_master['cnt'].shift(i) < df_master['cnt_tmp'], df_master['x_ind_h_nvi_10'] + df_master['tmp1'], \n\t\t\t\t\t\t\t\t\t\tdf_master['x_ind_h_nvi_10'])\n\tdf_master['cnt_tmp'] = df_master['cnt'].shift(i)\n\tdf_master['high_tmp'] = df_master['high'].shift(i)\n\t\n\n# low + cnt\t\ndf_master['x_ind_l_nvi_10'] = 100\ndf_master['cnt_tmp'] = df_master['cnt'].shift(10)\ndf_master['low_tmp'] = df_master['low'].shift(10) \nfor i in range(9, -1, -1):  \n\tdf_master['tmp1'] = np.where(df_master['low_tmp'] == 0, np.nan, \n\t\t\t\t\t\t\t\t   ((df_master['low'].shift(i) - df_master['low_tmp']) / df_master['low_tmp']) * 100)\n\tdf_master['x_ind_l_nvi_10'] = np.where(df_master['cnt'].shift(i) < df_master['cnt_tmp'], df_master['x_ind_l_nvi_10'] + df_master['tmp1'], \n\t\t\t\t\t\t\t\t\t\tdf_master['x_ind_l_nvi_10'])\n\tdf_master['cnt_tmp'] = df_master['cnt'].shift(i)\n\tdf_master['low_tmp'] = df_master['low'].shift(i)\n\t\t\n\t\n## PVI(Positive Volume Index)\n\n# end + cnt\t\t\t\t\t\t\t\t\t\t\ndf_master['x_ind_pvi_10'] = 100\ndf_master['cnt_tmp'] = df_master['cnt'].shift(10) \ndf_master['end_tmp'] = df_master['end'].shift(10) \nfor i in range(9, -1, -1):  \n\tdf_master['tmp1'] = np.where(df_master['end_tmp'] == 0, np.nan, \n\t\t\t\t\t\t\t\t   ((df_master['end'].shift(i) - df_master['end_tmp']) / df_master['end_tmp']) * 100)\n\tdf_master['x_ind_pvi_10'] = np.where(df_master['cnt'].shift(i) > df_master['cnt_tmp'], df_master['x_ind_pvi_10'] + df_master['tmp1'], \n\t\t\t\t\t\t\t\t\t\tdf_master['x_ind_pvi_10'])\n\tdf_master['cnt_tmp'] = df_master['cnt'].shift(i)\n\tdf_master['end_tmp'] = df_master['end'].shift(i)\n\t\n# high + cnt\t\t\t\t\t\t\t\t\t\t\ndf_master['x_ind_h_pvi_10'] = 100\ndf_master['cnt_tmp'] = df_master['cnt'].shift(10) \ndf_master['high_tmp'] = df_master['high'].shift(10) \nfor i in range(9, -1, -1):  \n\tdf_master['tmp1'] = np.where(df_master['high_tmp'] == 0, np.nan, \n\t\t\t\t\t\t\t\t   ((df_master['high'].shift(i) - df_master['high_tmp']) / df_master['high_tmp']) * 100)\n\tdf_master['x_ind_h_pvi_10'] = np.where(df_master['cnt'].shift(i) > df_master['cnt_tmp'], df_master['x_ind_h_pvi_10'] + df_master['tmp1'], \n\t\t\t\t\t\t\t\t\t\tdf_master['x_ind_h_pvi_10'])\n\tdf_master['cnt_tmp'] = df_master['cnt'].shift(i)\n\tdf_master['high_tmp'] = df_master['high'].shift(i)\n\t\n# low + cnt\t\t\t\t\t\t\t\t\t\t\ndf_master['x_ind_l_pvi_10'] = 100\ndf_master['cnt_tmp'] = df_master['cnt'].shift(10) \ndf_master['low_tmp'] = df_master['low'].shift(10) \nfor i in range(9, -1, -1):  \n\tdf_master['tmp1'] = np.where(df_master['low_tmp'] == 0, np.nan, \n\t\t\t\t\t\t\t\t   ((df_master['low'].shift(i) - df_master['low_tmp']) / df_master['low_tmp']) * 100)\n\tdf_master['x_ind_l_pvi_10'] = np.where(df_master['cnt'].shift(i) > df_master['cnt_tmp'], df_master['x_ind_l_pvi_10'] + df_master['tmp1'], \n\t\t\t\t\t\t\t\t\t\tdf_master['x_ind_l_pvi_10'])\n\tdf_master['cnt_tmp'] = df_master['cnt'].shift(i)\n\tdf_master['low_tmp'] = df_master['low'].shift(i)\n\n## Rule Feature\ndf_master['x_cls_01'] = np.where((df_master['open'] < df_master['end']) & (df_master['high'] > df_master['end']) & (df_master['high']/df_master['end'].shift(1) <=1.01), 1,\n\t\t\t\t\t    np.where((df_master['open'] < df_master['end']) & (df_master['high'] > df_master['end']), 2, 3))\n\t\t\t\t\t\t\ndl_list = df_master.columns[pd.Series(df_master.columns).str.startswith('x_cls_')]   \ndf_master[dl_list] = df_master[dl_list].astype(str) \n",
      "metadata": {
        "trusted": true
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "# 2. ëª¨ë¸ ì†Œê°œ\n\n## LightGBM\nLightGBM(ì´í•˜ LGBM)ì€ íŠ¸ë¦¬ ê¸°ë°˜ì˜ í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì¸ gradient boosting ë°©ì‹ì˜ í”„ë ˆì„ ì›Œí¬ì…ë‹ˆë‹¤.\n\nLGBMì€ ìœ ì‚¬í•œ ì•Œê³ ë¦¬ì¦˜ì¸ XGBoostì— ë¹„í•´ í›ˆë ¨ ì‹œê°„ì´ ì§§ê³  ì„±ëŠ¥ë„ ì¢‹ì•„ ë¶€ìŠ¤íŒ… ì•Œê³ ë¦¬ì¦˜ì—ì„œ ê°€ì¥ ë§ì€ ì£¼ëª©ì„ ë°›ê³  ìˆìŠµë‹ˆë‹¤. \n\nLGBMì˜ ê²½ìš° ë³µì¡í•œ ê²ƒì€ íŒŒë¼ë¯¸í„° íŠœë‹ì…ë‹ˆë‹¤. \n\nLGBMì€ 100ê°œ ì´ìƒì˜ íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ë ‡ê¸° ë•Œë¬¸ì— LGBMì˜ ê°€ì¥ ë² ì´ì§í•œ íŒŒë¼ë¯¸í„°ë¥¼ ì•„ëŠ” ê²ƒì´ êµ¬í˜„ ì‹œ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤. \n\n\n## LGBMì˜ ëŒ€í‘œì ì¸ íŒŒë¼ë¯¸í„°\n\n- **n_leaves** : ì „ì²´ Treeì˜ leave ìˆ˜ ì´ê³ , ë””í´íŠ¸ê°’ì€ 31ì…ë‹ˆë‹¤.\n\n- **n_estimators** : ìƒì„±í•  weak learnerì˜ ìˆ˜ì´ê³ , ë„ˆë¬´ í¬ë©´ ê³¼ëŒ€ì í•©ì´ ë°œìƒí•©ë‹ˆë‹¤.\n\n- **max_depth** :  Treeì˜ ìµœëŒ€ ê¹Šì´ë¥¼ ë§í•©ë‹ˆë‹¤. ì´ íŒŒë¼ë¯¸í„°ëŠ” ëª¨ë¸ ê³¼ì í•©ì„ ë‹¤ë£° ë•Œ ì‚¬ìš©ë©ë‹ˆë‹¤. ë§Œì•½ ëª¨ë¸ì´ ê³¼ì í•©ëœ ê²ƒ ê°™ë‹¤ê³  ëŠë¼ì‹ ë‹¤ë©´ max_depth ê°’ì„ ì¤„ì´ëŠ” ê²ƒì„ ì¶”ì²œë“œë¦½ë‹ˆë‹¤.\n\n- **learning_rate** : ìµœì¢… ê²°ê³¼ì— ëŒ€í•œ ê°ê°ì˜ Treeì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ë³€ìˆ˜ì…ë‹ˆë‹¤. GBMì€ ì´ˆê¸°ì˜ ì¶”ì •ê°’ì—ì„œ ì‹œì‘í•˜ì—¬ ê°ê°ì˜Tree ê²°ê³¼ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶”ì •ê°’ì„ ì—…ë°ì´íŠ¸ í•©ë‹ˆë‹¤. í•™ìŠµ íŒŒë¼ë¯¸í„°ëŠ” ì´ëŸ¬í•œ ì¶”ì •ì—ì„œ ë°œìƒí•˜ëŠ” ë³€í™”ì˜ í¬ê¸°ë¥¼ ì»¨íŠ¸ë¡¤í•©ë‹ˆë‹¤. ì¼ë°˜ì ì¸ ê°’ì€ 0.1, 0.001, 0.003 ë“±ë“±ì´ ìˆìŠµë‹ˆë‹¤.\n\n- **subsample** : weak learnerê°€ í•™ìŠµì— ì‚¬ìš©í•˜ëŠ” ë°ì´í„° ìƒ˜í”Œë§ ë¹„ìœ¨ì…ë‹ˆë‹¤. ë³´í†µ 0.5~ 1ì´ ì‚¬ìš©ë˜ë©° ê°’ì´ ë‚®ì„ìˆ˜ë¡ ê³¼ì í•©ì´ ë°©ì§€ë©ë‹ˆë‹¤.\n\n- **colsample_bytree** : ì»¬ëŸ¼ì„ ëœë¤ìœ¼ë¡œ ì¶”ì¶œí•˜ì—¬ ì‚¬ìš©í•´ ê°ê°ì˜ ë‹¤ì–‘ì„±ì„ ë†’ì…ë‹ˆë‹¤. ëœë¤í¬ë ˆìŠ¤íŠ¸ì— ìˆëŠ” ê¸°ëŠ¥ì´ë©°, ë³´í†µ ì •í™•ë„ë¥¼ ë†’ì´ëŠ” íš¨ê³¼ê°€ ìˆìŠµë‹ˆë‹¤.\n\n- **reg_alpha** : ê°€ì¤‘ì¹˜ì— ëŒ€í•œ L1 Regularization ì ìš© ê°’ì…ë‹ˆë‹¤. í”¼ì²˜ ê°œìˆ˜ê°€ ë§ì„ ë•Œ ì ìš©ì„ ê²€í† í•˜ë©° ì´ ê°’ì´ í´ ìˆ˜ë¡ ê³¼ì í•© ê°ì†Œ íš¨ê³¼ê°€ ìˆìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ 0ì…ë‹ˆë‹¤.\n\n- **reg_lambda** : ê°€ì¤‘ì¹˜ì— ëŒ€í•œ L2 Regularization ì ìš© ê°’ì…ë‹ˆë‹¤. í”¼ì²˜ ê°œìˆ˜ê°€ ë§ì„ ë•Œ ì ìš©ì„ ê²€í† í•˜ë©° ì´ ê°’ì´ í´ ìˆ˜ë¡ ê³¼ì í•© ê°ì†Œ íš¨ê³¼ê°€ ìˆìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ 0ì…ë‹ˆë‹¤.\n\n- **objective** : ëª©ì (ì†ì‹¤)í•¨ìˆ˜ë¡œ ì´ í•¨ìˆ˜ì˜ ê²°ê³¼ê°’ì´ ìµœì†Œí™”ë˜ëŠ” ë°©í–¥ìœ¼ë¡œ í•™ìŠµí•œë‹¤. íšŒê·€ì¸ì§€, ë¶„ë¥˜ì¸ì§€ ë“±ì— ë”°ë¼ ì˜µì…˜ì„ ë‹¤ë¥´ê²Œ ì„ íƒí•´ì•¼ í•œë‹¤. regression, binary, multicalss ëª¨ë‘ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n\n- **min_data_in_leaf** : Leafê°€ ê°€ì§€ê³  ìˆëŠ” ìµœì†Œí•œì˜ ë ˆì½”ë“œ ìˆ˜ì…ë‹ˆë‹¤. ë””í´íŠ¸ê°’ì€ 20ìœ¼ë¡œ ìµœì  ê°’ì…ë‹ˆë‹¤. ê³¼ì í•©ì„ í•´ê²°í•  ë•Œ ì‚¬ìš©ë˜ëŠ” íŒŒë¼ë¯¸í„°ì…ë‹ˆë‹¤.\n\n- **random_state** :  ëœë¤ ì‹œë“œ ê³ ì • ê°’ìœ¼ë¡œì„œ, ë°˜ë“œì‹œ ê³ ì •í•´ë‘ê³  íŠœë‹í•´ì•¼ í•©ë‹ˆë‹¤.\n\nì§€ê¸ˆ ë³´ì‹œê¸°ì—” ë„ˆë¬´ ì–´ë ¤ìš´ ë‚´ìš©ì´ ë§ì£ ?\n\nì§€ê¸ˆì€ ì–´ë ¤ìš¸ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ë¨¸ì‹ ëŸ¬ë‹ê³¼ ê´€ë ¨ëœ ê°œë…ì´ ë‚˜ì˜¤ê¸° ë•Œë¬¸ì¸ë°, ë‚˜ì¤‘ì— ë°ì´ì»¤ ì—¬ëŸ¬ë¶„ë“¤ì´ ë¨¸ì‹ ëŸ¬ë‹ ê¸°ì´ˆì™€ ì˜ì‚¬ê²°ì •ë‚˜ë¬´(Decision Tree), ëœë¤í¬ë ˆìŠ¤íŠ¸(Random Forest) ë“±ì„ ê³µë¶€í•˜ì‹œê²Œ ëœë‹¤ë©´ ë¬´ìŠ¨ ì†Œë¦¬ì¸ì§€ ì´í•´í•˜ì‹¤ ìˆ˜ ìˆì„ê²ë‹ˆë‹¤.\n\n# 3. ëª¨ë¸ë§\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "## ë¶„ì„ ëª¨ì§‘ë‹¨ ìƒì„±\n# public, privateì— í•„ìš”í•œ ë°ì´í„° ë‚ ì§œ\npub_base_dt = '20211029'  \npri_base_dt = '20211126'  \n## Public, Private í‰ê°€ ê¸°ê°„\ndl_predict_pub_day = ['2021-11-01', '2021-11-02', '2021-11-03', '2021-11-04', '2021-11-05']   \ndl_predict_pri_day = ['2021-11-29', '2021-11-30', '2021-12-01', '2021-12-02', '2021-12-03']   \n\n## ë¶„ì„ ëª¨ì§‘ë‹¨ ìƒì„±\ndf_mst = df_master.query(\"num >=101 & cnt > 0 \")\t\n# numì€ ì—¬ê¸°ì„œ ì¸ë±ìŠ¤ë¥¼ ì˜ë¯¸í•˜ëŠ”ë°, ì£¼ê°€ë¥¼ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ì„  í•˜ë£¨ì˜ ë°ì´í„°ê°€ ì•„ë‹ˆë¼, ìˆ˜ì‹­ì¼ ì „ê¹Œì§€ì˜ ë°ì´í„°ë„ í•„ìš”í•˜ê¸° ë•Œë¬¸ì— ì•ì˜ 100ê°œì˜ ë°ì´í„°ëŠ” ë°°ì œ.\ndl_col_1 = ['dt', 'code', 'amt']     #ë‚ ì§œ, ì¢…ëª©ì½”ë“œ, ê±°ë˜ëŒ€ê¸ˆ\ndl_col_2 = df_mst.columns[pd.Series(df_mst.columns).str.startswith('y_')].values.tolist()   \n#y_ë¡œ ì‹œì‘í•˜ëŠ” (í–¥í›„ 5ì¼ì¹˜ ì£¼ê°€ í–¥ë°©)ê°’ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë¶ˆëŸ¬ì˜¤ê¸°.\ndl_x1 = df_mst.columns[pd.Series(df_mst.columns).str.startswith('x_')].values.tolist()\n#x_ë¡œ ì‹œì‘í•˜ëŠ” ê°’(í™˜ìœ¨ê³¼ ì£¼ê°€ì§€ìˆ˜)ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë¶ˆëŸ¬ì˜¨ë‹¤.  \ndl_x2 = ['end', 'avg_amt_20', 'end_usdkrw']  #ì¢…ê°€, ê±°ë˜ëŒ€ê¸ˆ 20ì¼ ì´ë™í‰ê· , ì¢…ê°€\ndl_x = dl_x1 + dl_x2 \ndf_mst = df_mst[dl_col_1 + dl_col_2 + dl_x]  # ë¶„ì„ì— í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì¶”ì¶œí•´ df_mstì— ì €ì¥.\n\n\n## í•™ìŠµ ì¡°ê±´ ì„¤ì •\ndl_look_after = [1, 2, 3, 4, 5]                        # ì˜ˆì¸¡ê¸°ê°„\ndl_n_trin = [800, 400, 200, 100, 50]     # í•™ìŠµ ë°ì´íƒ€ê±´ìˆ˜\ndl_target = ['y_rt_01d_eeup', 'y_rt_02d_eeup', 'y_rt_03d_eeup', 'y_rt_04d_eeup', 'y_rt_05d_eeup']   # Target Name\ndl_yn     = ['y_01d_yn', 'y_02d_yn', 'y_03d_yn', 'y_04d_yn', 'y_05d_yn']                            # Target ë¶ˆëŠ¥ ì—¬ë¶€\n\ndf_m2_pre_c1_tot = pd.DataFrame()\ndf_m2_pre_c2_tot = pd.DataFrame()\n\n## ì˜ˆì¸¡ê¸°ê°„ë³„ ëª¨ë¸ë§\nfor look in dl_look_after:\n\n\tprint(\"\\n ===> look_after : \",  look)\n\t\n\tdf_mst_tt = df_mst.copy()\n\n\tn_trin_sample = dl_n_trin[look-1]   \n\trandom.seed(123)\n\t\n\tstr_target            = dl_target[look-1]      \n\tstr_yn                = dl_yn[look-1]     \n\tlook_after            = look      \n\tdf_mst_tt.rename(columns = {str_target:'Target'}, inplace = True)    \n\t\n\t## í•™ìŠµ ë° ì˜ˆì¸¡ ì¡°ê±´\t\n    # c1ì€ publicì„ ì˜ˆì¸¡í•˜ê¸° ìœ„í•œ ë°ì´í„°, c2ëŠ” privateì„ ì˜ˆì¸¡í•˜ê¸° ìœ„í•œ ë°ì´í„°\n    # m1ì€ í›ˆë ¨ìš© ë°ì´í„°, m2ëŠ” ì˜ˆì¸¡ìš© ë°ì´í„°\n\tdf_m1_tt_c1 = df_mst_tt[(df_mst_tt['dt'] >= '20120101') & (df_mst_tt['dt'] < pub_base_dt)]   \t           \n\tdf_m1_tt_c2 = df_mst_tt[(df_mst_tt['dt'] >= '20120101') & (df_mst_tt['dt'] < pri_base_dt)]   \n\tdf_m2_tt_c1 = df_mst_tt[(df_mst_tt['dt'] == pub_base_dt)]  \n\tdf_m2_tt_c2 = df_mst_tt[(df_mst_tt['dt'] == pri_base_dt)]  \n\tdf_m1_tt_c1 = df_m1_tt_c1[df_m1_tt_c1[str_yn]==1]   \n\tdf_m1_tt_c2 = df_m1_tt_c2[df_m1_tt_c2[str_yn]==1]   \t\n\tdf_m2_tt_c1 = df_m2_tt_c1[df_m2_tt_c1['code'].isin(stock_list['code'])] \n\tdf_m2_tt_c2 = df_m2_tt_c2[df_m2_tt_c2['code'].isin(stock_list['code'])] \n\t\n\t## Target Scaling\t\n    # ì´ìƒì¹˜(ë„ˆë¬´ ê·¹ë‹¨ì ì¸ ë°ì´í„°)ë¥¼ ì œê±°í•˜ê¸° ìœ„í•´, ìƒìœ„ 20í¼ì—ì„œ ìƒìœ„ 80í¼ ì•ˆì— ë“¤ì–´ê°€ëŠ” ê°’ë§Œ ì¶”ì¶œ\n\ttarget_out1 = df_m1_tt_c1['Target'].describe(percentiles = [0.2, 0.8])\n\ttarget_out2 = df_m1_tt_c2['Target'].describe(percentiles = [0.2, 0.8])\n\tdf_m1_tt_c1 = df_m1_tt_c1[(df_m1_tt_c1['Target'] >= target_out1['20%']) & (df_m1_tt_c1['Target'] < target_out1['80%'])]\n\tdf_m1_tt_c2 = df_m1_tt_c2[(df_m1_tt_c2['Target'] >= target_out2['20%']) & (df_m1_tt_c2['Target'] < target_out2['80%'])]\n\t\n\n\tdef f_featuring(df_m1_tt, df_m2_tt):\n\t\t\n\t\trandom.seed(123)   \n\t\t\n\t\t## Sampling\t\t\n        # í•™ìŠµ ë°ì´í„°ë¥¼ ëœë¤í•˜ê²Œ ì¶”ì¶œí•˜ì—¬ ì‚¬ìš©\n\t\trows = random.sample(df_m1_tt.index.tolist(), n_trin_sample)     \n\t\tdf_m1_sam = df_m1_tt.loc[rows]\t\t\t\n\t\tdf_m1_sam = df_m1_sam.sort_values(by=['dt'], axis=0)    \t\t\n\t\tdf_m2_sam = df_m2_tt.sort_values(by=['dt'], axis=0)   \n\t\t\n\t\t## X, Y ë¶„ë¦¬\t\t\t\n\t\tdl_y = df_m1_sam.columns[pd.Series(df_m1_sam.columns).str.startswith('Target')].values.tolist()  \t\t\t\n\t\tdf_m1_x = df_m1_sam[dl_x]\t\n\t\tdf_m2_x = df_m2_sam[dl_x]\t\n\t\tdf_m1_y = df_m1_sam[dl_y]\t\n\t\tdf_m2_y = df_m2_sam[dl_y]\n\t\t\t\n\t\t## Missing ì²˜ë¦¬\n\t\tdf_m1_x = df_m1_x.replace([np.inf, -np.inf], np.nan)\t\n\t\tdf_m2_x = df_m2_x.replace([np.inf, -np.inf], np.nan)\n        # ë’¤ì—ì„œ ë¡œê·¸ë³€í™˜ì„ í•´ì£¼ì–´ì•¼ í•˜ëŠ”ë°, log(inf) = 0 ì´ë¯€ë¡œ, 0ì´ ë˜ì§€ ì•Šê²Œ ë³€í™˜ í›„ ì œê±°\n        \n\t\tdf_m1_x.dropna(how='any', axis=1, inplace=True)  \n        # how='all'ì€ í•œ í–‰ì´ ê°€ì§€ëŠ” ëª¨ë“  ì»¬ëŸ¼ì´ ê²°ì¸¡ì¹˜ì—¬ì•¼ drop\n\t\tdl_tot_cols = df_m1_x.columns                    \n\t\tdf_m2_x = df_m2_x[dl_tot_cols]                   \n\t\t\t\n\t\tdl_num_cols = df_m1_x._get_numeric_data().columns                    \n\t\tif len(dl_num_cols) >= 1:\n\t\t\timp = SimpleImputer(missing_values=np.nan, strategy='median')\n            # SimpleImputerëŠ” ê²°ì¸¡ì¹˜ë¥¼ ëŒ€ì²´í•˜ëŠ” ê¸°ë²• ì¤‘ í•˜ë‚˜ë¡œ, ìˆ«ìí˜•(ì—°ì†í˜•) ë°ì´í„°ëŠ” strategy = 'median'ìœ¼ë¡œ ì§€ì •í•˜ì—¬ ì¤‘ì•™ê°’ìœ¼ë¡œ ëŒ€ì²´\n            \n\t\t\timp = imp.fit(df_m1_x[dl_num_cols])\n\t\t\tdf_m1_x[dl_num_cols] = imp.transform(df_m1_x[dl_num_cols])\n\t\t\tdf_m2_x[dl_num_cols] = imp.transform(df_m2_x[dl_num_cols])\n\t\t\t\n\t\tdl_cls_cols = df_m1_x.select_dtypes(include=['object']).columns.tolist()\t\t\n\t\tif len(dl_cls_cols) >= 1:\t\t\n            # ë¬¸ìí˜• ë°ì´í„°ëŠ” ê²°ì¸¡ì¹˜ë¥¼ 'missing'ì´ë¼ëŠ” ë¬¸ìë¡œ ëŒ€ì²´\n\t\t\tdf_m1_x[dl_cls_cols] = df_m1_x[dl_cls_cols].fillna('missing')\n\t\t\tdf_m2_x[dl_cls_cols] = df_m2_x[dl_cls_cols].fillna('missing')\n\n\t\t## Unique ë³€ìˆ˜ ì œì™¸ -> í•œ ë³€ìˆ˜ì˜ ê°’ì´ í•˜ë‚˜ë°–ì— ì—†ëŠ” ë³€ìˆ˜ë¥¼ ì œê±°\n\t\tdf_col_list = df_m1_x.apply(pd.Series.nunique) != 1    \n\t\tdf_m1_x = df_m1_x.loc[:, df_col_list]\n\t\tdf_m2_x = df_m2_x.loc[:, df_col_list]\t\t\t\t\n\n\t\t## ì—°ì†í˜• ë³€ìˆ˜ Log ë³€í™˜ \t\t\n        # ë¡œê·¸ë³€í™˜ì€ í° ìˆ˜ë¥¼ ì‘ê²Œ ë§Œë“¤ê±°ë‚˜, ë³µì¡í•œ ê³„ì‚°ì„ ê°„í¸í•˜ê²Œ í•  ê²½ìš° ì‚¬ìš©, ì™œë„ì™€ ì²¨ë„ë¥¼ ì¤„ì—¬ì„œ ë°ì´í„° ë¶„ì„ ì‹œ ì˜ë¯¸ìˆëŠ” ê²°ê³¼ë¥¼ ë„ì¶œí•˜ê¸° ìœ„í•¨.\n\t\tdl_num_cols = df_m1_x._get_numeric_data().columns   \n\t\tfor col in dl_num_cols:\t\t  \n\t\t\tdf_m1_x[col] = np.where(df_m1_x[col] < 0, -np.log(1 + -df_m1_x[col]), np.log(1 + df_m1_x[col]))   \n\t\t\tdf_m2_x[col] = np.where(df_m2_x[col] < 0, -np.log(1 + -df_m2_x[col]), np.log(1 + df_m2_x[col]))   \n\t\t\t\t\t\n\t\t## ë³€ìˆ˜ í‘œì¤€í™” \n        # ì—°ì†í˜• ë°ì´í„°ëŠ” ë²”ì£¼í˜• ë°ì´í„°ì™€ ë‹¬ë¦¬ ì •ê·œí™” ê³¼ì •ì´ í•„ìš”. ëŒ€ë¶€ë¶„ì˜ ì•Œê³ ë¦¬ì¦˜ë“¤ì´ ë³€ìˆ˜ì˜ ë²”ìœ„ì— ì˜í–¥ì„ ë°›ê¸° ë•Œë¬¸ì— ê° ë³€ìˆ˜ê°€ ê°€ì§€ëŠ” ê°’ë“¤ì˜ ìˆ«ì ë²”ìœ„ê°€ ë‹¤ë¥¼ ê²½ìš°, ì´ë¥¼ ì¼ì •í•œ ë²”ìœ„ë¡œ ë§ì¶°ì¤˜ì•¼í•¨.\n\t\tdl_num_cols = df_m1_x._get_numeric_data().columns   \n\t\tscaler = StandardScaler().fit(df_m1_x[dl_num_cols])           \n\t\tdf_m1_x[dl_num_cols] = scaler.transform(df_m1_x[dl_num_cols])  \n\t\tdf_m2_x[dl_num_cols] = scaler.transform(df_m2_x[dl_num_cols])  \n\t\t\n\t\t## One Hot Encoding \t\t\n        # ì›-í•« ì¸ì½”ë”©ì€ ë‹¨ì–´ ì§‘í•©ì˜ í¬ê¸°ë¥¼ ë²¡í„°ì˜ ì°¨ì›ìœ¼ë¡œ í•˜ê³ , í‘œí˜„í•˜ê³  ì‹¶ì€ ê°’ì˜ ì¸ë±ìŠ¤ì— 1ì˜ ê°’ì„ ë¶€ì—¬í•˜ê³ , ë‹¤ë¥¸ ì¸ë±ìŠ¤ì—ëŠ” 0ì„ ë¶€ì—¬í•˜ëŠ” ë°ì´í„°í„°ì˜ ë²¡í„° í‘œí˜„ ë°©ì‹. \n\t\tdl_cls_cols = df_m1_x.select_dtypes(include=['object']).columns.tolist()\t\t\n\t\tdf_m1_x_dumy = pd.get_dummies(df_m1_x[dl_cls_cols], prefix=dl_cls_cols)   \n\t\tdf_m2_x_dumy = pd.get_dummies(df_m2_x[dl_cls_cols], prefix=dl_cls_cols)\n\t\tdl_col_m1 = df_m1_x_dumy.columns\t\n\t\tdl_col_m2 = df_m2_x_dumy.columns\n\n\t\tdl_col_m1_m2 = list(set(dl_col_m1) - set(dl_col_m2))  \n\t\tif len(dl_col_m1_m2) >= 1:\n\t\t\tfor col in dl_col_m1_m2:\n\t\t\t\tdf_m2_x_dumy[col] = 0\t\t\t\t\t\n\n\t\tdf_m1_x = pd.concat([df_m1_x[dl_num_cols], df_m1_x_dumy], axis=1)\n\t\tdf_m2_x = pd.concat([df_m2_x[dl_num_cols], df_m2_x_dumy], axis=1)\t\n\t\tdf_m1_x, df_m2_x = df_m1_x.align(df_m2_x, join='left', axis=1, fill_value=0)\n\n\t\t## ìƒê´€ë¶„ì„\n        # ìƒê´€ê³„ìˆ˜ê°€ ë§¤ìš° ë†’ì€(ì ˆëŒ“ê°’ì´ 0.95ë³´ë‹¤ í°) ì»¬ëŸ¼ì„ ì œê±°.\n\t\tcorr_matrix = df_m1_x.corr()\t\t\n\t\tdf_corr_upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))  \n\t\tto_drop = [column for column in df_corr_upper.columns if (any(df_corr_upper[column] >= 0.95) | any(df_corr_upper[column] < -0.95))]   \n\t\tdf_m1_x.drop(to_drop, axis=1, inplace=True)\n\t\tdf_m2_x.drop(to_drop, axis=1, inplace=True)\n\t\t\n\t\t## Feature ì•ˆì •ì„± ë¶„ì„\t\t\n\t\tif len(df_m1_x.columns) > 120:   \n\t\t\tnum = 120                    \n\t\telse:\n\t\t\tnum = len(df_m1_x.columns)   \n\t\tmodel = SelectKBest(f_regression, k= num) \n# SelectKBestëŠ” ë°ì´í„°ì— ì»¬ëŸ¼ì´ ë„ˆë¬´ ë§ì€ ê²½ìš° ëª¨ë¸ì˜ ì„¤ëª…ë ¥ì„ ê°€ì¥ ë†’ì¼ ìˆ˜ ìˆëŠ” Kê°œì˜ ì»¬ëŸ¼ë§Œ ì„ íƒí•˜ê²Œ í•˜ëŠ” ëª¨ë“ˆ.\n# ë°ì´í„°ì— ì»¬ëŸ¼ì´ ë„ˆë¬´ ë§ì„ ê²½ìš° ëª¨ë¸ í•™ìŠµì‹œê°„ì´ ì˜¤ë˜ê±¸ë¦¬ê¸°ë„ í•˜ê³ , ê³¼ëŒ€ì í•©ì´ë¼ëŠ” ë¬¸ì œê°€ ë°œìƒ.        \n# f_regressionì€ íšŒê·€ë¶„ì„ì˜ F-testì„ ì§„í–‰í•˜ëŠ” ëª¨ë“ˆ. SelectKBestì—ì„œ ìµœì ì˜ ë³€ìˆ˜ ì¡°í•©ì„ ì°¾ì•„ë‚´ê¸° ìœ„í•´ ì‚¬ìš©.\n\t\tcol_list = pd.DataFrame(df_m1_x.columns, columns=['col'])\n\t\tint_num = int(len(df_m1_x)/3)\n\t\tfit = model.fit(df_m1_x[:int_num], df_m1_y[:int_num])\n\t\tscore_list_1 = pd.DataFrame(model.scores_, columns=['score'])\n\t\tfit = model.fit(df_m1_x[int_num:int_num*2], df_m1_y  [int_num:int_num*2])\n\t\tscore_list_2 = pd.DataFrame(model.scores_, columns=['score'])\n\t\tfit = model.fit(df_m1_x[int_num*2:], df_m1_y[int_num*2:])\n\t\tscore_list_3 = pd.DataFrame(model.scores_, columns=['score'])\t\n\t\tdf_importance = pd.concat([col_list, score_list_1, score_list_2, score_list_3], axis=1)     \n\t\tdf_importance['mean'] = df_importance.iloc[:, [1, 2, 3]].min(1)\n\t\tdf_importance['rank'] = df_importance['mean'].rank(ascending=0)  \n\t\tdf_m1_x = df_m1_x[df_importance.loc[df_importance['rank'] <= num, 'col']]\n\t\tdf_m2_x = df_m2_x[df_importance.loc[df_importance['rank'] <= num, 'col']]\t\t\n\t\t\t\t\t\t\n\t\treturn df_m1_x, df_m2_x, df_m1_y, df_m2_y, df_m2_sam\n\t\t\n\tdf_m1_x_c1, df_m2_x_c1, df_m1_y_c1, df_m2_y_c1, df_m2_sam_c1 = f_featuring(df_m1_tt_c1, df_m2_tt_c1)\n\tdf_m1_x_c2, df_m2_x_c2, df_m1_y_c2, df_m2_y_c2, df_m2_sam_c2 = f_featuring(df_m1_tt_c2, df_m2_tt_c2)\n\n\t## Model Fitting\t\t\n\tgbl = globals()\n    # globals() í•¨ìˆ˜ëŠ” íŠ¹ì • ëª¨ë“ˆë‚´ì—ì„œ ì‚¬ìš©ë˜ëŠ” ì „ì—­ ë³€ìˆ˜ë“¤ì˜ ë³€ìˆ˜ ì´ë¦„ ë° í˜„ì¬ ê°’ ë“±ì„ ì•Œê³  ì‹¶ì„ ë•Œ ì‚¬ìš©í•˜ëŠ” í•¨ìˆ˜. \n    # globals í•¨ìˆ˜ëŠ” ì½”ë“œë‚´ì˜ ì „ì—­ ë³€ìˆ˜ì˜ ì´ë¦„ê³¼ í˜„ì¬ ê°’ì„ ì¶œë ¥. \n    # ì—¬ê¸°ì„œ ì „ì—­ë³€ìˆ˜ë€, ì§€ì—­ë³€ìˆ˜ë‘ ë°˜ëŒ€ë˜ëŠ” ê°œë…ìœ¼ë¡œ í•˜ë‚˜ì˜ ë°˜ë³µë¬¸ì´ë‚˜ ì¡°ê±´ë¬¸, ì‚¬ìš©ìì •ì˜í•¨ìˆ˜ ë“±ì—ì„œ ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•  ë•Œ í•´ë‹¹ ë³€ìˆ˜ë¥¼ êµ¬ë¬¸ ë°–ì—ì„œë„ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë³€ìˆ˜ë¥¼ ì˜ë¯¸.\n    \n    \n\tdef f_modeling_1(case_flg):\n\n\t\tdf_m1_x = gbl['df_m1_x_' + case_flg]\n\t\tdf_m2_x = gbl['df_m2_x_' + case_flg]\n\t\tdf_m1_y = gbl['df_m1_y_' + case_flg]\n\t\tdf_m2_y = gbl['df_m2_y_' + case_flg]\t\n\t\tdf_m2_sam = gbl['df_m2_sam_' + case_flg]\n\t\ttrain_data = lgb.Dataset(df_m1_x, label = df_m1_y)\t\n\t\tparameters = {\n\t\t\t'n_leaves':10,\n\t\t\t'n_estimators':80, \n\t\t\t'max_depth':-1,  \n\t\t\t'learning_rate':0.01, \n\t\t\t'subsample':1,\n\t\t\t'colsample_bytree':0.8,\n\t\t\t'reg_alpha':0.1,\n\t\t\t'reg_lambda':1,\n\t\t\t'objective': 'regression',\n\t\t\t'min_data':1,\n\t\t\t'min_data_in_bin':1,\t\n\t\t\t'random_state' : 123} \t\t\t\n        # ì¸ì ì„¤ëª…ì€ ì•ì„  2ì¥ì—ì„œ ë‹¤ë£¨ì—ˆìŠµë‹ˆë‹¤.\n        \n\t\tfit = lgb.train(parameters, train_data, num_boost_round=5000)\t\n\t\tdf_m1_pre = pd.DataFrame(fit.predict(df_m1_x))\n\t\tdf_m2_pre = pd.DataFrame(fit.predict(df_m2_x))\n\t\t\t\t\t\t\t\n\t\t## Predict\n\t\tdf_m2_pre.rename(columns = {0:\"score\"}, inplace = True)\n\t\tdf_m2_pre = pd.concat([df_m2_pre.reset_index(drop=True), \n\t\t\t\t\t\t\t   df_m2_sam[['Target', 'dt', 'code', 'amt', 'end']].reset_index(drop=True)], axis=1)\t\t\n\t\tdf_m2_pre['end_a1'] = df_m2_pre['end'] * df_m2_pre['Target']\t\t\t\n\t\tdf_m2_pre['end_a1_pred'] = df_m2_pre['end'] * df_m2_pre['score'] \n\t\tdf_m2_pre['model'] = 'M1' \n\t\tdf_m2_pre['case'] = case_flg\n\t\tdf_m2_pre['look_after'] = look_after\n\n\t\treturn df_m2_pre\n\n\tdf_m2_pre_c1 = f_modeling_1('c1')       \n\tdf_m2_pre_c2 = f_modeling_1('c2')\t\n\tdf_m2_pre_c1_tot = df_m2_pre_c1_tot.append(df_m2_pre_c1)\n\tdf_m2_pre_c2_tot = df_m2_pre_c2_tot.append(df_m2_pre_c2)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 9,
      "outputs": [
        {
          "name": "stdout",
          "text": "\n ===> look_after :  1\n[LightGBM] [Warning] Unknown parameter: n_leaves\n[LightGBM] [Warning] Unknown parameter: n_leaves\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002100 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29841\n[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 120\n[LightGBM] [Info] Start training from score 1.000430\n[LightGBM] [Warning] Unknown parameter: n_leaves\n[LightGBM] [Warning] Unknown parameter: n_leaves\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000600 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 29841\n[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 120\n[LightGBM] [Info] Start training from score 1.000730\n\n ===> look_after :  2\n[LightGBM] [Warning] Unknown parameter: n_leaves\n[LightGBM] [Warning] Unknown parameter: n_leaves\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001400 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29841\n[LightGBM] [Info] Number of data points in the train set: 400, number of used features: 120\n[LightGBM] [Info] Start training from score 1.000858\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] Unknown parameter: n_leaves\n[LightGBM] [Warning] Unknown parameter: n_leaves\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001100 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29841\n[LightGBM] [Info] Number of data points in the train set: 400, number of used features: 120\n[LightGBM] [Info] Start training from score 1.000716\n\n ===> look_after :  3\n[LightGBM] [Warning] Unknown parameter: n_leaves\n[LightGBM] [Warning] Unknown parameter: n_leaves\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000500 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 23028\n[LightGBM] [Info] Number of data points in the train set: 200, number of used features: 120\n[LightGBM] [Info] Start training from score 1.002942\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] Unknown parameter: n_leaves\n[LightGBM] [Warning] Unknown parameter: n_leaves\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000800 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 23227\n[LightGBM] [Info] Number of data points in the train set: 200, number of used features: 120\n[LightGBM] [Info] Start training from score 1.002424\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n ===> look_after :  4\n[LightGBM] [Warning] Unknown parameter: n_leaves\n[LightGBM] [Warning] Unknown parameter: n_leaves\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000300 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 11630\n[LightGBM] [Info] Number of data points in the train set: 100, number of used features: 120\n[LightGBM] [Info] Start training from score 1.000973\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] Unknown parameter: n_leaves\n[LightGBM] [Warning] Unknown parameter: n_leaves\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000300 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 11630\n[LightGBM] [Info] Number of data points in the train set: 100, number of used features: 120\n[LightGBM] [Info] Start training from score 1.003380\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n ===> look_after :  5\n[LightGBM] [Warning] Unknown parameter: n_leaves\n[LightGBM] [Warning] Unknown parameter: n_leaves\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000200 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 6053\n[LightGBM] [Info] Number of data points in the train set: 50, number of used features: 120\n[LightGBM] [Info] Start training from score 0.999910\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] Unknown parameter: n_leaves\n[LightGBM] [Warning] Unknown parameter: n_leaves\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000000 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 5910\n[LightGBM] [Info] Number of data points in the train set: 50, number of used features: 120\n[LightGBM] [Info] Start training from score 1.001304\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "\n**ì—¬ê¸°ì„œ ì ê¹!** âœ‹\n\n\n> [Warning] No further splits with positive gain, best gain: -inf \n\n\nì´ë¼ëŠ” ê²½ê³ ë¬¸êµ¬ê°€ ë§ì´ ëœ° í…ë°ìš”. ì›ë˜ ìœ„ ì½”ë“œëŠ” ëª¨ë“  ì£¼ì‹ì¢…ëª©ì˜ ë°ì´í„°ë¥¼ í™œìš©í•˜ëŠ” ì½”ë“œì¸ë°, ìš°ë¦¬ëŠ” ì‚¼ì„±ì „ìì˜ ë°ì´í„°ë§Œ ë‹¤ë£¨ê³  ìˆê¸° ë•Œë¬¸ì— ë°ì´í„°ê°€ ë¶€ì¡±í•´ì„œ\nìœ„ì™€ ê°™ì€ ê²½ê³ ë¬¸êµ¬ê°€ ëœ° ê²ƒì…ë‹ˆë‹¤. ë¬´ì‹œí•˜ê³  ë„˜ì–´ê°€ì…”ë„ ì¢‹ì•„ìš” :)",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "ì´ìƒìœ¼ë¡œ â€˜ëª¨ë¸ ì†Œê°œ ë° í•™ìŠµâ€™ ì£¼ì œ Stage 5ì´ì˜€ìŠµë‹ˆë‹¤.\në§ˆì§€ë§‰ Stageì¸ Stage 6ì—ëŠ” ìµœì¢…ì ìœ¼ë¡œ ì˜ˆì¸¡ëœ ë°ì´í„°ë¥¼ í›„ì²˜ë¦¬ í•´ì£¼ê³ , ì œì¶œ íŒŒì¼ê¹Œì§€ ë§Œë“œëŠ” ë‚´ìš©ìœ¼ë¡œ ë§ˆë¬´ë¦¬ ì§“ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.\n\në‹¤ìŒì— ë˜ ë§Œë‚˜ìš”!ğŸ«¶",
      "metadata": {}
    }
  ]
}