{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "[코알라] 주식 종료 가격 예측 경진대회 Stage 6 : 모델 후처리 및 마무리\n\n안녕하세요. 데이크루 4기 코알라🐨 팀입니다. \n\n저희는 📈주식 종료 가격 예측 경진대회를 주제로 PBL를 수행합니다.\n\n이번 활동을 통해 논리적인 접근 방식으로 모든 문제를 풀어갈 수 있는 데이커가 되는 것을 최종 목표로 하고 있습니다. \n\nStage 6은 PBL을 구성하는 6가지 단계 중 마지막 단계로서 모델 후처리 및 마무리 내용을 담고있습니다.\n\n다음의 포스팅은 데이크루 4기 활동으로 인하여 작성되었음을 알려드립니다.\n\n\n\n\n\n# Stage 6.\n# 1. Review\n\nStage 6에 들어가려면 Stage 5까지의 모든 코드를 입력해야지만 가능합니다.\n\n간단하게 코드를 복습한다는 마음으로 천천히 코드를 읽어보며, 아래 코드를 실행시켜 주세요!\n\n\n",
      "metadata": {},
      "id": "b054a297"
    },
    {
      "cell_type": "code",
      "source": "import micropip\nawait micropip.install('requests')",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "id": "5c32f239-85ce-4222-82d6-a3b16b789e7b"
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nimport datetime\nimport requests as req\nimport lightgbm as lgb\nfrom sklearn import linear_model\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.feature_selection import SelectKBest, f_regression, f_classif\nfrom sklearn import metrics\nimport os\nimport sys\nimport random\nimport warnings\n\nwarnings.filterwarnings(action='ignore')\nos.chdir('./practice_data')\n\n## Public, Private 예측 기준 일자\npub_base_dt = '20211029'  \npri_base_dt = '20211126'  \n\n## Public, Private 평가 기간\ndl_predict_pub_day = ['2021-11-01', '2021-11-02', '2021-11-03', '2021-11-04', '2021-11-05']   \ndl_predict_pri_day = ['2021-11-29', '2021-11-30', '2021-12-01', '2021-12-02', '2021-12-03']   \n\n\n## 과거 상장폐지종목 추출 \ndf_out_tt1 = pd.read_csv('코스피상폐현황.csv', encoding='utf-8') \ndf_out_tt2 = pd.read_csv('코스닥상폐현황.csv', encoding='utf-8') \n\ndf_out_tt1['market'] = 'KOSPI'\ndf_out_tt2['market'] = 'KOSDAQ'\ndf_out_tt = pd.concat([df_out_tt1, df_out_tt2])\ndf_out_tt.rename(columns = {\"종목코드\":\"code\", \"회사명\":\"code_nm\", \"폐지일자\":\"out_dt\", \"폐지사유\":\"out_desc\"}, inplace = True)\ndf_out_tt['code'] = df_out_tt['code'].astype(str) \ndf_out_tt['code'] = df_out_tt['code'].str.zfill(6) \ndf_out_tt['out_dt'] = pd.to_datetime(df_out_tt['out_dt'])\ndf_out_tt = df_out_tt[[\"code\", \"code_nm\", \"out_dt\", \"out_desc\", \"market\"]]\n\n## 현재 상장종목 전체 추출 : FinanceDataReader\ndf_in_tt = pd.read_csv('종목리스트.csv', encoding='utf-8')\ndf_in_tt.columns = ['code', 'isu_cd', 'code_nm', 'market', 'dept', 'close', 'changecode', 'changes', 'chagesratio', \n                    'open', 'high', 'low', 'volume', 'amount', 'marcap', 'stocks', 'marketId']\ndf_in_tt = df_in_tt[(df_in_tt['market'] !='KONEX') &                \n                    (df_in_tt.code.str.startswith('5') != True) &   \n                    (df_in_tt.code.str.startswith('6') != True) &   \n                    (df_in_tt.code.str.startswith('7') != True) &   \n                    (df_in_tt.code.str.len() == 6)]\ndf_in_tt['in_yn'] = 1  \ndf_in_tt['code'] = df_in_tt['code'].astype(str) \ndf_in_tt['code'] = df_in_tt['code'].str.zfill(6) \ndf_in_tt['close'] = df_in_tt['close'].astype(str)\ndf_in_tt['changecode'] = df_in_tt['close'].astype(str)\n\n## 과거 상장폐지종목 + 현재 상장종목 결합\nend_dt = datetime.datetime.now().strftime('%Y%m%d')   \ndf_stock_code = pd.merge(df_out_tt, df_in_tt, how='outer', on='code', suffixes=('_old', '_new'))\ndf_stock_code['in_yn'] = np.where(df_stock_code['in_yn'].notnull(), df_stock_code['in_yn'], 0)\ndf_stock_code['market'] = np.where(df_stock_code['market_new'].notnull(), df_stock_code['market_new'], df_stock_code['market_old'])\ndf_stock_code['code_nm'] = np.where(df_stock_code['code_nm_new'].notnull(), df_stock_code['code_nm_new'], df_stock_code['code_nm_old'])\ndf_stock_code['base_dt'] = pd.to_datetime(end_dt)\ndf_stock_code.rename(columns = {\"ListingDate\":\"in_dt\"}, inplace = True) \ndf_stock_code = df_stock_code.sort_values(by=['code', 'base_dt'], axis=0, ascending=[True, False])  \ndf_stock_code = df_stock_code.drop_duplicates(['code'], keep='first')\ndf_stock_code = df_stock_code[['code','code_nm','in_yn','market','out_dt','out_desc','base_dt']]\ndf_stock_code = df_stock_code[df_stock_code['code']=='005930']\n\ndf_price = pd.read_csv('주가파일.csv', encoding='utf-8')\ndf_price['dt'] = pd.to_datetime(df_price['dt'])\ndf_price['dt_base'] = pd.to_datetime(df_price['dt_base'])\ndf_price['code'] = df_price['code'].astype(str)\ndf_price['code'] = df_price['code'].str.zfill(6)\n\ndf_usdkrw = pd.read_csv('환율파일.csv', encoding='utf-8')    \ndf_index = pd.read_csv('주가지수.csv', encoding='utf-8')\ndf_index['dt'] = pd.to_datetime(df_index['dt'])\ndf_usdkrw['dt'] = pd.to_datetime(df_usdkrw['dt'])\n\n## 학습 대상 종목 선정 \nstock_list = pd.read_csv(\"./stock_list.csv\")\nstock_list['종목코드'] = stock_list['종목코드'].apply(lambda x : str(x).zfill(6))\nstock_list.rename(columns = {\"종목코드\":\"code\"}, inplace = True) \n\ndf_master = df_price[(df_price['open'] > 0) & (df_price['end'] > 0) & (df_price['cnt'] > 0)]\ndf_master['amt']  = df_master['end'] * df_master['cnt']   \ndf_amt = df_master.groupby(['code'], as_index=False)[['end', 'cnt', 'amt']].mean()\ndf_amt = df_amt[(df_amt['end'] >= 3000) & (df_amt['amt'] >= 2000000000)]     \ndl_amt = df_amt['code'].values.tolist() \ndl_200 = stock_list['code'].values.tolist() \ndl_amt = set(dl_amt + dl_200)\ndf_master = df_master[df_master['code'].isin(dl_amt)]   \n\n## Target 생성\ndf_master = df_master.sort_values(by=['code', 'dt'], axis=0, ascending=[True, False])  \ndf_master['num'] = df_master.groupby('code')['dt'].rank(ascending=True).astype(int)\ndf_master['y_01d_yn']  = np.where(df_master['code'] == df_master['code'].shift(1), 1, 0)  \ndf_master['y_02d_yn']  = np.where(df_master['code'] == df_master['code'].shift(2), 1, 0)  \ndf_master['y_03d_yn']  = np.where(df_master['code'] == df_master['code'].shift(3), 1, 0)  \ndf_master['y_04d_yn']  = np.where(df_master['code'] == df_master['code'].shift(4), 1, 0)  \ndf_master['y_05d_yn']  = np.where(df_master['code'] == df_master['code'].shift(5), 1, 0)  \ndf_master['y_rt_01d_eeup']  = df_master['end'].shift(1) / df_master['end']\ndf_master['y_rt_02d_eeup']  = df_master['end'].shift(2) / df_master['end']\ndf_master['y_rt_03d_eeup']  = df_master['end'].shift(3) / df_master['end']\ndf_master['y_rt_04d_eeup']  = df_master['end'].shift(4) / df_master['end']\ndf_master['y_rt_05d_eeup']  = df_master['end'].shift(5) / df_master['end']\n\ndf_master = df_master.sort_values(by=['code', 'dt'], axis=0) \ndf_master = pd.merge(df_master, df_index[['dt', 'end_kpi', 'end_ksd']], how='left', on='dt')\ndf_master = pd.merge(df_master, df_stock_code[['code', 'market']], how='left', on='code')\ndf_master['x_rt_end_index']  = np.where(df_master['market'] == 'KOSPI', df_master['end'] / df_master['end_kpi'], \n                                        df_master['end'] / df_master['end_ksd'])\ndf_master = pd.merge(df_master, df_usdkrw[['dt', 'end_usdkrw']], how='left', on='dt')\ndf_master['x_rt_end_usdkrw'] = df_master['end'] / df_master['end_usdkrw']\n\n## 시/저/고/저 파생\ndf_master['avg_amt_20'] = df_master['amt'].rolling(window=20).mean() \ndf_master['x_rt_h_l']  = np.where(df_master['low'] == 0,  np.nan, df_master['high'] / df_master['low'])      \ndf_master['x_rt_e_s']  = np.where(df_master['open'] == 0,  np.nan, df_master['end'] / df_master['open'])   \ndf_master['x_rt_e_l']  = np.where(df_master['low'] == 0,  np.nan, df_master['end'] / df_master['low']) \ndf_master['x_rt_h_s']  = np.where(df_master['open'] == 0,  np.nan, df_master['high'] / df_master['open'])   \ndf_master['x_rt_s_l']  = np.where(df_master['low'] == 0,  np.nan, df_master['open'] / df_master['low'])  \ndf_master['x_rt_bf_1']  = np.where(df_master['end'].shift(1) == 0,   np.nan, df_master['end'] / df_master['end'].shift(1))\n\n## 과거 평균 대비 이격도 Feature \nk  = 3; k2 = 10; k3 = 40; k4 = 80\n\ndl_num_cols = ['open', 'high', 'low', 'end', 'amt', 'end_kpi', 'end_ksd', 'x_rt_end_index',\n               'x_rt_bf_1', 'x_rt_e_s', 'x_rt_e_l', 'end_usdkrw', 'x_rt_end_usdkrw' ] \n\ndl_cols =[('x_rt_bf_1_' + w) for w in dl_num_cols]\ndf_master[dl_cols]  = np.where(df_master[dl_num_cols].shift(1) == 0,  np.nan, df_master[dl_num_cols] / df_master[dl_num_cols].shift(1))\n\ndl_cols =[('x_rt_ma_k_' + w) for w in dl_num_cols]\ndf_master[dl_cols]  = np.where(df_master[dl_num_cols].rolling(window=k).mean() == 0,  np.nan, \n                      (df_master[dl_num_cols]-df_master[dl_num_cols].rolling(window=k).mean()) / df_master[dl_num_cols].rolling(window=k2).mean())  \ndf_master[dl_cols] = np.where(df_master[dl_num_cols] >= df_master[dl_num_cols].rolling(window=k).mean(), \n                      abs(df_master[dl_cols]), -abs(df_master[dl_cols]))                                                \n                        \ndl_cols =[('x_rt_ma_k2_' + w) for w in dl_num_cols]\ndf_master[dl_cols]  = np.where(df_master[dl_num_cols].rolling(window=k2).mean() == 0,  np.nan, \n                      (df_master[dl_num_cols]-df_master[dl_num_cols].rolling(window=k2).mean()) / df_master[dl_num_cols].rolling(window=k2).mean())  \ndf_master[dl_cols] = np.where(df_master[dl_num_cols] >= df_master[dl_num_cols].rolling(window=k2).mean(), \n                      abs(df_master[dl_cols]), -abs(df_master[dl_cols]))\n                        \ndl_cols =[('x_rt_ma_k_k2_' + w) for w in dl_num_cols]\ndf_master[dl_cols]  = np.where(df_master[dl_num_cols].rolling(window=k2).mean() == 0,  np.nan, \n                      (df_master[dl_num_cols].rolling(window=k).mean()-df_master[dl_num_cols].rolling(window=k2).mean()) / df_master[dl_num_cols].rolling(window=k2).mean())  \ndf_master[dl_cols] = np.where(df_master[dl_num_cols].rolling(window=k).mean() >= df_master[dl_num_cols].rolling(window=k2).mean(), \n                      abs(df_master[dl_cols]), -abs(df_master[dl_cols]))\n\ndl_cols =[('x_rt_ma_k3_' + w) for w in dl_num_cols]\ndf_master[dl_cols]  = np.where(df_master[dl_num_cols].rolling(window=k3).mean() == 0,  np.nan, \n\t\t\t\t\t\t\t (df_master[dl_num_cols]-df_master[dl_num_cols].rolling(window=k3).mean()) / df_master[dl_num_cols].rolling(window=k2).mean())  \ndf_master[dl_cols] = np.where(df_master[dl_num_cols] >= df_master[dl_num_cols].rolling(window=k3).mean(), \n\t\t\t\t\t\t\t abs(df_master[dl_cols]), -abs(df_master[dl_cols]))\n\t\t\t\t\t\t\t \ndl_cols =[('x_rt_ma_k_k3_' + w) for w in dl_num_cols]\ndf_master[dl_cols]  = np.where(df_master[dl_num_cols].rolling(window=k3).mean() == 0,  np.nan, \n\t\t\t\t\t\t\t (df_master[dl_num_cols].rolling(window=k).mean()-df_master[dl_num_cols].rolling(window=k3).mean()) / df_master[dl_num_cols].rolling(window=k2).mean())  \ndf_master[dl_cols] = np.where(df_master[dl_num_cols].rolling(window=k).mean() >= df_master[dl_num_cols].rolling(window=k3).mean(), \n\t\t\t\t\t\t\t abs(df_master[dl_cols]), -abs(df_master[dl_cols]))\n\t\t\t\t\t\t\t \ndl_cols =[('x_rt_ma_k2_k3_' + w) for w in dl_num_cols]\ndf_master[dl_cols]  = np.where(df_master[dl_num_cols].rolling(window=k3).mean() == 0,  np.nan, \n\t\t\t\t\t\t\t (df_master[dl_num_cols].rolling(window=k2).mean()-df_master[dl_num_cols].rolling(window=k3).mean()) / df_master[dl_num_cols].rolling(window=k2).mean())  \ndf_master[dl_cols] = np.where(df_master[dl_num_cols].rolling(window=k2).mean() >= df_master[dl_num_cols].rolling(window=k3).mean(), \n\t\t\t\t\t\t\t abs(df_master[dl_cols]), -abs(df_master[dl_cols]))\t\t\t\t\t\t\t \n\t\t\t\t\t\t\t \ndl_cols =[('x_rt_ma_k4_' + w) for w in dl_num_cols]\ndf_master[dl_cols]  = np.where(df_master[dl_num_cols].rolling(window=k4).mean() == 0,  np.nan, \n\t\t\t\t\t\t\t (df_master[dl_num_cols]-df_master[dl_num_cols].rolling(window=k4).mean()) / df_master[dl_num_cols].rolling(window=k2).mean())  \ndf_master[dl_cols] = np.where(df_master[dl_num_cols] >= df_master[dl_num_cols].rolling(window=k4).mean(), \n\t\t\t\t\t\t\t abs(df_master[dl_cols]), -abs(df_master[dl_cols]))\n\t\t\t\t\t\t\t \ndl_cols =[('x_rt_ma_k_k4_' + w) for w in dl_num_cols]\ndf_master[dl_cols]  = np.where(df_master[dl_num_cols].rolling(window=k4).mean() == 0,  np.nan, \n\t\t\t\t\t\t\t (df_master[dl_num_cols].rolling(window=k).mean()-df_master[dl_num_cols].rolling(window=k4).mean()) / df_master[dl_num_cols].rolling(window=k2).mean())  \ndf_master[dl_cols] = np.where(df_master[dl_num_cols].rolling(window=k).mean() >= df_master[dl_num_cols].rolling(window=k4).mean(), \n\t\t\t\t\t\t\t abs(df_master[dl_cols]), -abs(df_master[dl_cols]))\n\t\t\t\t\t\t\t \ndl_cols =[('x_rt_ma_k2_k4_' + w) for w in dl_num_cols]\ndf_master[dl_cols]  = np.where(df_master[dl_num_cols].rolling(window=k4).mean() == 0,  np.nan, \n\t\t\t\t\t\t\t (df_master[dl_num_cols].rolling(window=k2).mean()-df_master[dl_num_cols].rolling(window=k4).mean()) / df_master[dl_num_cols].rolling(window=k2).mean())  \ndf_master[dl_cols] = np.where(df_master[dl_num_cols].rolling(window=k2).mean() >= df_master[dl_num_cols].rolling(window=k4).mean(), \n\t\t\t\t\t\t\t abs(df_master[dl_cols]), -abs(df_master[dl_cols]))\n\t\t\t\t\t\t\t \ndl_cols =[('x_rt_ma_k3_k4_' + w) for w in dl_num_cols]\ndf_master[dl_cols]  = np.where(df_master[dl_num_cols].rolling(window=k4).mean() == 0,  np.nan, \n\t\t\t\t\t\t\t (df_master[dl_num_cols].rolling(window=k3).mean()-df_master[dl_num_cols].rolling(window=k4).mean()) / df_master[dl_num_cols].rolling(window=k2).mean())  \ndf_master[dl_cols] = np.where(df_master[dl_num_cols].rolling(window=k3).mean() >= df_master[dl_num_cols].rolling(window=k4).mean(), \n\t\t\t\t\t\t\t abs(df_master[dl_cols]), -abs(df_master[dl_cols]))\n\n## 단순이동평균 대비 지수이동평균 대비 이격도\nfor col in dl_num_cols:\n\tstr_ma05 = 'ma05_' + col\n\tstr_ema05 = 'ema05_' + col\n\tstr_rt_ema05_ma05 = 'x_rt_ema05_ma05_' + col\n\tdf_master[str_ma05] = df_master[col].rolling(window=5).mean() \t\t\n\tdf_master[str_ema05]  = df_master[col].shift(5) \n\ttmp1 = 0.7 \t\n\tfor i in range(5):\n\t\tdf_master[str_ema05]  = (df_master[col].shift(5-1-i) * tmp1) + (df_master[str_ema05] * (1-tmp1))\t\t\n\tdf_master[str_rt_ema05_ma05] = np.where(df_master[str_ma05] == 0,  np.nan, (df_master[str_ema05]-df_master[str_ma05]) / df_master[str_ma05])  \n\tdf_master[str_rt_ema05_ma05] = np.where(df_master[str_ema05] >= df_master[str_ma05], abs(df_master[str_rt_ema05_ma05]), -abs(df_master[str_rt_ema05_ma05]))\t\t   \n\n\tstr_ma20 = 'ma20_' + col\n\tstr_ema20 = 'ema20_' + col\n\tstr_rt_ema20_ma20 = 'x_rt_ema20_ma20_' + col\n\tdf_master[str_ma20] = df_master[col].rolling(window=20).mean() \t\t\n\tdf_master[str_ema20]  = df_master[col].shift(20) \n\ttmp1 = 0.7 \t\n\tfor i in range(20):\n\t\tdf_master[str_ema20]  = (df_master[col].shift(20-1-i) * tmp1) + (df_master[str_ema20] * (1-tmp1))\t\t\n\tdf_master[str_rt_ema20_ma20] = np.where(df_master[str_ma20] == 0,  np.nan, (df_master[str_ema20]-df_master[str_ma20]) / df_master[str_ma20])  \n\tdf_master[str_rt_ema20_ma20] = np.where(df_master[str_ema20] >= df_master[str_ma20], abs(df_master[str_rt_ema20_ma20]), -abs(df_master[str_rt_ema20_ma20]))\t\t   \n\n\tstr_ma40 = 'ma40_' + col\n\tstr_ema40 = 'ema40_' + col\n\tstr_rt_ema40_ma40 = 'x_rt_ema40_ma40_' + col\n\tdf_master[str_ma40] = df_master[col].rolling(window=40).mean() \t\t\n\tdf_master[str_ema40]  = df_master[col].shift(40) \n\ttmp1 = 0.7 \t\n\tfor i in range(40):\n\t\tdf_master[str_ema40]  = (df_master[col].shift(40-1-i) * tmp1) + (df_master[str_ema40] * (1-tmp1))\t\t\n\tdf_master[str_rt_ema40_ma40] = np.where(df_master[str_ma40] == 0,  np.nan, (df_master[str_ema40]-df_master[str_ma40]) / df_master[str_ma40])  \n\tdf_master[str_rt_ema40_ma40] = np.where(df_master[str_ema40] >= df_master[str_ma40], abs(df_master[str_rt_ema40_ma40]), -abs(df_master[str_rt_ema40_ma40]))\t\t   \n\n\tstr_ma80 = 'ma80_' + col\n\tstr_ema80 = 'ema80_' + col\n\tstr_rt_ema80_ma80 = 'x_rt_ema80_ma80_' + col\n\tdf_master[str_ma80] = df_master[col].rolling(window=80).mean() \t\t\n\tdf_master[str_ema80]  = df_master[col].shift(80) \n\ttmp1 = 0.7 \t\n\tfor i in range(80):\n\t\tdf_master[str_ema80]  = (df_master[col].shift(80-1-i) * tmp1) + (df_master[str_ema80] * (1-tmp1))\t\t\n\tdf_master[str_rt_ema80_ma80] = np.where(df_master[str_ma80] == 0,  np.nan, (df_master[str_ema80]-df_master[str_ma80]) / df_master[str_ma80])  \n\tdf_master[str_rt_ema80_ma80] = np.where(df_master[str_ema80] >= df_master[str_ma80], abs(df_master[str_rt_ema80_ma80]), -abs(df_master[str_rt_ema80_ma80]))\t\t   \n\n\t\n## Lag 변수\t\t\ndl_code = ['x_rt_bf_1', 'x_rt_h_l', 'x_rt_e_s', 'x_rt_e_l']\nfor m in range(10):   \n\tfor code in dl_code:\n\t\tstr_x = 'x_lag_' + code + str(m+1) \t\n\t\tdf_master[str_x] = df_master[code].shift(m+1)\n\t\n\n## NVI(Negative Volume Index)\n\n# end + cnt\t\ndf_master['x_ind_nvi_10'] = 100\ndf_master['cnt_tmp'] = df_master['cnt'].shift(10)\ndf_master['end_tmp'] = df_master['end'].shift(10) \nfor i in range(9, -1, -1):  \n\tdf_master['tmp1'] = np.where(df_master['end_tmp'] == 0, np.nan, \n\t\t\t\t\t\t\t\t   ((df_master['end'].shift(i) - df_master['end_tmp']) / df_master['end_tmp']) * 100)\n\tdf_master['x_ind_nvi_10'] = np.where(df_master['cnt'].shift(i) < df_master['cnt_tmp'], df_master['x_ind_nvi_10'] + df_master['tmp1'], \n\t\t\t\t\t\t\t\t\t\tdf_master['x_ind_nvi_10'])\n\tdf_master['cnt_tmp'] = df_master['cnt'].shift(i)\n\tdf_master['end_tmp'] = df_master['end'].shift(i)\n\t\n# high + cnt\t\ndf_master['x_ind_h_nvi_10'] = 100\ndf_master['cnt_tmp'] = df_master['cnt'].shift(10)\ndf_master['high_tmp'] = df_master['high'].shift(10) \nfor i in range(9, -1, -1):  \n\tdf_master['tmp1'] = np.where(df_master['high_tmp'] == 0, np.nan, \n\t\t\t\t\t\t\t\t   ((df_master['high'].shift(i) - df_master['high_tmp']) / df_master['high_tmp']) * 100)\n\tdf_master['x_ind_h_nvi_10'] = np.where(df_master['cnt'].shift(i) < df_master['cnt_tmp'], df_master['x_ind_h_nvi_10'] + df_master['tmp1'], \n\t\t\t\t\t\t\t\t\t\tdf_master['x_ind_h_nvi_10'])\n\tdf_master['cnt_tmp'] = df_master['cnt'].shift(i)\n\tdf_master['high_tmp'] = df_master['high'].shift(i)\n\t\n\n# low + cnt\t\ndf_master['x_ind_l_nvi_10'] = 100\ndf_master['cnt_tmp'] = df_master['cnt'].shift(10)\ndf_master['low_tmp'] = df_master['low'].shift(10) \nfor i in range(9, -1, -1):  \n\tdf_master['tmp1'] = np.where(df_master['low_tmp'] == 0, np.nan, \n\t\t\t\t\t\t\t\t   ((df_master['low'].shift(i) - df_master['low_tmp']) / df_master['low_tmp']) * 100)\n\tdf_master['x_ind_l_nvi_10'] = np.where(df_master['cnt'].shift(i) < df_master['cnt_tmp'], df_master['x_ind_l_nvi_10'] + df_master['tmp1'], \n\t\t\t\t\t\t\t\t\t\tdf_master['x_ind_l_nvi_10'])\n\tdf_master['cnt_tmp'] = df_master['cnt'].shift(i)\n\tdf_master['low_tmp'] = df_master['low'].shift(i)\n\t\t\n\t\n## PVI(Positive Volume Index)\n\n# end + cnt\t\t\t\t\t\t\t\t\t\t\ndf_master['x_ind_pvi_10'] = 100\ndf_master['cnt_tmp'] = df_master['cnt'].shift(10) \ndf_master['end_tmp'] = df_master['end'].shift(10) \nfor i in range(9, -1, -1):  \n\tdf_master['tmp1'] = np.where(df_master['end_tmp'] == 0, np.nan, \n\t\t\t\t\t\t\t\t   ((df_master['end'].shift(i) - df_master['end_tmp']) / df_master['end_tmp']) * 100)\n\tdf_master['x_ind_pvi_10'] = np.where(df_master['cnt'].shift(i) > df_master['cnt_tmp'], df_master['x_ind_pvi_10'] + df_master['tmp1'], \n\t\t\t\t\t\t\t\t\t\tdf_master['x_ind_pvi_10'])\n\tdf_master['cnt_tmp'] = df_master['cnt'].shift(i)\n\tdf_master['end_tmp'] = df_master['end'].shift(i)\n\t\n# high + cnt\t\t\t\t\t\t\t\t\t\t\ndf_master['x_ind_h_pvi_10'] = 100\ndf_master['cnt_tmp'] = df_master['cnt'].shift(10) \ndf_master['high_tmp'] = df_master['high'].shift(10) \nfor i in range(9, -1, -1):  \n\tdf_master['tmp1'] = np.where(df_master['high_tmp'] == 0, np.nan, \n\t\t\t\t\t\t\t\t   ((df_master['high'].shift(i) - df_master['high_tmp']) / df_master['high_tmp']) * 100)\n\tdf_master['x_ind_h_pvi_10'] = np.where(df_master['cnt'].shift(i) > df_master['cnt_tmp'], df_master['x_ind_h_pvi_10'] + df_master['tmp1'], \n\t\t\t\t\t\t\t\t\t\tdf_master['x_ind_h_pvi_10'])\n\tdf_master['cnt_tmp'] = df_master['cnt'].shift(i)\n\tdf_master['high_tmp'] = df_master['high'].shift(i)\n\t\n# low + cnt\t\t\t\t\t\t\t\t\t\t\ndf_master['x_ind_l_pvi_10'] = 100\ndf_master['cnt_tmp'] = df_master['cnt'].shift(10) \ndf_master['low_tmp'] = df_master['low'].shift(10) \nfor i in range(9, -1, -1):  \n\tdf_master['tmp1'] = np.where(df_master['low_tmp'] == 0, np.nan, \n\t\t\t\t\t\t\t\t   ((df_master['low'].shift(i) - df_master['low_tmp']) / df_master['low_tmp']) * 100)\n\tdf_master['x_ind_l_pvi_10'] = np.where(df_master['cnt'].shift(i) > df_master['cnt_tmp'], df_master['x_ind_l_pvi_10'] + df_master['tmp1'], \n\t\t\t\t\t\t\t\t\t\tdf_master['x_ind_l_pvi_10'])\n\tdf_master['cnt_tmp'] = df_master['cnt'].shift(i)\n\tdf_master['low_tmp'] = df_master['low'].shift(i)\n\n## Rule Feature\ndf_master['x_cls_01'] = np.where((df_master['open'] < df_master['end']) & (df_master['high'] > df_master['end']) & (df_master['high']/df_master['end'].shift(1) <=1.01), 1,\n\t\t\t\t\t    np.where((df_master['open'] < df_master['end']) & (df_master['high'] > df_master['end']), 2, 3))\n\t\t\t\t\t\t\ndl_list = df_master.columns[pd.Series(df_master.columns).str.startswith('x_cls_')]   \ndf_master[dl_list] = df_master[dl_list].astype(str)     \n\n## 분석 모집단 생성\ndf_mst = df_master.query(\"num >=101 & cnt > 0 \")\t\ndl_col_1 = ['dt', 'code', 'amt']\t\ndl_col_2 = df_mst.columns[pd.Series(df_mst.columns).str.startswith('y_')].values.tolist()   \ndl_x1 = df_mst.columns[pd.Series(df_mst.columns).str.startswith('x_')].values.tolist()  \ndl_x2 = ['end', 'avg_amt_20', 'end_usdkrw']  \ndl_x = dl_x1 + dl_x2 \ndf_mst = df_mst[dl_col_1 + dl_col_2 + dl_x]\n\n## 학습 조건 설정\ndl_look_after = [1, 2, 3, 4, 5]                        # 예측기간\ndl_n_trin = [800, 400, 200, 100, 50]     # 학습 데이타건수\ndl_target = ['y_rt_01d_eeup', 'y_rt_02d_eeup', 'y_rt_03d_eeup', 'y_rt_04d_eeup', 'y_rt_05d_eeup']   # Target Name\ndl_yn     = ['y_01d_yn', 'y_02d_yn', 'y_03d_yn', 'y_04d_yn', 'y_05d_yn']                            # Target 불능 여부\n\ndf_m2_pre_c1_tot = pd.DataFrame()\ndf_m2_pre_c2_tot = pd.DataFrame()\n\n## 예측기간별 모델링\nfor look in dl_look_after:\n\n\tprint(\"\\n ===> look_after : \",  look)\n\t\n\tdf_mst_tt = df_mst.copy()\n\n\tn_trin_sample = dl_n_trin[look-1]   \n\trandom.seed(123)\n\t\n\tstr_target            = dl_target[look-1]      \n\tstr_yn                = dl_yn[look-1]     \n\tlook_after            = look      \n\tdf_mst_tt.rename(columns = {str_target:'Target'}, inplace = True)    \n\t\n\t## 학습 및 예측 조건\t\n\tdf_m1_tt_c1 = df_mst_tt[(df_mst_tt['dt'] >= '20120101') & (df_mst_tt['dt'] < pub_base_dt)]   \t           \n\tdf_m1_tt_c2 = df_mst_tt[(df_mst_tt['dt'] >= '20120101') & (df_mst_tt['dt'] < pri_base_dt)]   \n\tdf_m2_tt_c1 = df_mst_tt[(df_mst_tt['dt'] == pub_base_dt)]  \n\tdf_m2_tt_c2 = df_mst_tt[(df_mst_tt['dt'] == pri_base_dt)]  \n\tdf_m1_tt_c1 = df_m1_tt_c1[df_m1_tt_c1[str_yn]==1]   \n\tdf_m1_tt_c2 = df_m1_tt_c2[df_m1_tt_c2[str_yn]==1]   \t\n\tdf_m2_tt_c1 = df_m2_tt_c1[df_m2_tt_c1['code'].isin(stock_list['code'])] \n\tdf_m2_tt_c2 = df_m2_tt_c2[df_m2_tt_c2['code'].isin(stock_list['code'])] \n\t\n\t## Target Scaling\t\n\ttarget_out1 = df_m1_tt_c1['Target'].describe(percentiles = [0.2, 0.8])\n\ttarget_out2 = df_m1_tt_c2['Target'].describe(percentiles = [0.2, 0.8])\n\tdf_m1_tt_c1 = df_m1_tt_c1[(df_m1_tt_c1['Target'] >= target_out1['20%']) & (df_m1_tt_c1['Target'] < target_out1['80%'])]\n\tdf_m1_tt_c2 = df_m1_tt_c2[(df_m1_tt_c2['Target'] >= target_out2['20%']) & (df_m1_tt_c2['Target'] < target_out2['80%'])]\n\t\n\n\tdef f_featuring(df_m1_tt, df_m2_tt):\n\t\t\n\t\trandom.seed(123)   \n\t\t\n\t\t## Sampling\t\t\n\t\trows = random.sample(df_m1_tt.index.tolist(), n_trin_sample)     \n\t\tdf_m1_sam = df_m1_tt.loc[rows]\t\t\t\n\t\tdf_m1_sam = df_m1_sam.sort_values(by=['dt'], axis=0)    \t\t\n\t\tdf_m2_sam = df_m2_tt.sort_values(by=['dt'], axis=0)   \n\t\t\n\t\t## X, Y 분리\t\t\t\n\t\tdl_y = df_m1_sam.columns[pd.Series(df_m1_sam.columns).str.startswith('Target')].values.tolist()  \t\t\t\n\t\tdf_m1_x = df_m1_sam[dl_x]\t\n\t\tdf_m2_x = df_m2_sam[dl_x]\t\n\t\tdf_m1_y = df_m1_sam[dl_y]\t\n\t\tdf_m2_y = df_m2_sam[dl_y]\n\t\t\t\n\t\t## Missing 처리\n\t\tdf_m1_x = df_m1_x.replace([np.inf, -np.inf], np.nan)\t\n\t\tdf_m2_x = df_m2_x.replace([np.inf, -np.inf], np.nan)\n\t\tdf_m1_x.dropna(how='any', axis=1, inplace=True)  \n\t\tdl_tot_cols = df_m1_x.columns                    \n\t\tdf_m2_x = df_m2_x[dl_tot_cols]                   \n\t\t\t\n\t\tdl_num_cols = df_m1_x._get_numeric_data().columns                    \n\t\tif len(dl_num_cols) >= 1:\n\t\t\timp = SimpleImputer(missing_values=np.nan, strategy='median')   \n\t\t\timp = imp.fit(df_m1_x[dl_num_cols])\n\t\t\tdf_m1_x[dl_num_cols] = imp.transform(df_m1_x[dl_num_cols])\n\t\t\tdf_m2_x[dl_num_cols] = imp.transform(df_m2_x[dl_num_cols])\n\t\t\t\n\t\tdl_cls_cols = df_m1_x.select_dtypes(include=['object']).columns.tolist()\t\t\n\t\tif len(dl_cls_cols) >= 1:\t\t\n\t\t\tdf_m1_x[dl_cls_cols] = df_m1_x[dl_cls_cols].fillna('missing')\n\t\t\tdf_m2_x[dl_cls_cols] = df_m2_x[dl_cls_cols].fillna('missing')\n\n\t\t## Unique 변수 제외\n\t\tdf_col_list = df_m1_x.apply(pd.Series.nunique) != 1    \n\t\tdf_m1_x = df_m1_x.loc[:, df_col_list]\n\t\tdf_m2_x = df_m2_x.loc[:, df_col_list]\t\t\t\t\n\n\t\t## 변수 Log 변환 \t\t\n\t\tdl_num_cols = df_m1_x._get_numeric_data().columns   \n\t\tfor col in dl_num_cols:\t\t  \n\t\t\tdf_m1_x[col] = np.where(df_m1_x[col] < 0, -np.log(1 + -df_m1_x[col]), np.log(1 + df_m1_x[col]))   \n\t\t\tdf_m2_x[col] = np.where(df_m2_x[col] < 0, -np.log(1 + -df_m2_x[col]), np.log(1 + df_m2_x[col]))   \n\t\t\t\t\t\n\t\t## 변수 표준화 \n\t\tdl_num_cols = df_m1_x._get_numeric_data().columns   \n\t\tscaler = StandardScaler().fit(df_m1_x[dl_num_cols])           \n\t\tdf_m1_x[dl_num_cols] = scaler.transform(df_m1_x[dl_num_cols])  \n\t\tdf_m2_x[dl_num_cols] = scaler.transform(df_m2_x[dl_num_cols])  \n\t\t\n\t\t## One Hot Encoding \t\t\n\t\tdl_cls_cols = df_m1_x.select_dtypes(include=['object']).columns.tolist()\t\t\n\t\tdf_m1_x_dumy = pd.get_dummies(df_m1_x[dl_cls_cols], prefix=dl_cls_cols)   \n\t\tdf_m2_x_dumy = pd.get_dummies(df_m2_x[dl_cls_cols], prefix=dl_cls_cols)\n\t\tdl_col_m1 = df_m1_x_dumy.columns\t\n\t\tdl_col_m2 = df_m2_x_dumy.columns\n\n\t\tdl_col_m1_m2 = list(set(dl_col_m1) - set(dl_col_m2))  \n\t\tif len(dl_col_m1_m2) >= 1:\n\t\t\tfor col in dl_col_m1_m2:\n\t\t\t\tdf_m2_x_dumy[col] = 0\t\t\t\t\t\n\n\t\tdf_m1_x = pd.concat([df_m1_x[dl_num_cols], df_m1_x_dumy], axis=1)\n\t\tdf_m2_x = pd.concat([df_m2_x[dl_num_cols], df_m2_x_dumy], axis=1)\t\n\t\tdf_m1_x, df_m2_x = df_m1_x.align(df_m2_x, join='left', axis=1, fill_value=0)\n\n\t\t## 상관분석\n\t\tcorr_matrix = df_m1_x.corr()\t\t\n\t\tdf_corr_upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))  \n\t\tto_drop = [column for column in df_corr_upper.columns if (any(df_corr_upper[column] >= 0.95) | any(df_corr_upper[column] < -0.95))]   \n\t\tdf_m1_x.drop(to_drop, axis=1, inplace=True)\n\t\tdf_m2_x.drop(to_drop, axis=1, inplace=True)\n\t\t\n\t\t## Feature 안정성 분석\t\t\n\t\tif len(df_m1_x.columns) > 120:   \n\t\t\tnum = 120                    \n\t\telse:\n\t\t\tnum = len(df_m1_x.columns)   \n\t\tmodel = SelectKBest(f_regression, k= num)                \n\t\tcol_list = pd.DataFrame(df_m1_x.columns, columns=['col'])\n\t\tint_num = int(len(df_m1_x)/3)\n\t\tfit = model.fit(df_m1_x[:int_num], df_m1_y[:int_num])\n\t\tscore_list_1 = pd.DataFrame(model.scores_, columns=['score'])\n\t\tfit = model.fit(df_m1_x[int_num:int_num*2], df_m1_y  [int_num:int_num*2])\n\t\tscore_list_2 = pd.DataFrame(model.scores_, columns=['score'])\n\t\tfit = model.fit(df_m1_x[int_num*2:], df_m1_y[int_num*2:])\n\t\tscore_list_3 = pd.DataFrame(model.scores_, columns=['score'])\t\n\t\tdf_importance = pd.concat([col_list, score_list_1, score_list_2, score_list_3], axis=1)     \n\t\tdf_importance['mean'] = df_importance.iloc[:, [1, 2, 3]].min(1)\n\t\tdf_importance['rank'] = df_importance['mean'].rank(ascending=0)  \n\t\tdf_m1_x = df_m1_x[df_importance.loc[df_importance['rank'] <= num, 'col']]\n\t\tdf_m2_x = df_m2_x[df_importance.loc[df_importance['rank'] <= num, 'col']]\t\t\n\t\t\t\t\t\t\n\t\treturn df_m1_x, df_m2_x, df_m1_y, df_m2_y, df_m2_sam\n\t\t\n\tdf_m1_x_c1, df_m2_x_c1, df_m1_y_c1, df_m2_y_c1, df_m2_sam_c1 = f_featuring(df_m1_tt_c1, df_m2_tt_c1)\n\tdf_m1_x_c2, df_m2_x_c2, df_m1_y_c2, df_m2_y_c2, df_m2_sam_c2 = f_featuring(df_m1_tt_c2, df_m2_tt_c2)\n\n\t## Model Fitting\t\t\n\tgbl = globals()\n\tdef f_modeling_1(case_flg):\n\n\t\tdf_m1_x = gbl['df_m1_x_' + case_flg]\n\t\tdf_m2_x = gbl['df_m2_x_' + case_flg]\n\t\tdf_m1_y = gbl['df_m1_y_' + case_flg]\n\t\tdf_m2_y = gbl['df_m2_y_' + case_flg]\t\n\t\tdf_m2_sam = gbl['df_m2_sam_' + case_flg]\n\t\ttrain_data = lgb.Dataset(df_m1_x, label = df_m1_y)\t\n\t\tparameters = {\n\t\t\t'n_leaves':10,\n\t\t\t'n_estimators':80, \n\t\t\t'max_depth':-1,  \n\t\t\t'learning_rate':0.01, \n\t\t\t'subsample':1,\n\t\t\t'colsample_bytree':0.8,\n\t\t\t'reg_alpha':0.1,\n\t\t\t'reg_lambda':1,\n\t\t\t'objective': 'regression',\n\t\t\t'min_data':1,\n\t\t\t'min_data_in_bin':1,\t\n\t\t\t'random_state' : 123} \t\t\t\n\t\tfit = lgb.train(parameters, train_data, num_boost_round=5000)\t\n\t\tdf_m1_pre = pd.DataFrame(fit.predict(df_m1_x))\n\t\tdf_m2_pre = pd.DataFrame(fit.predict(df_m2_x))\n\t\t\t\t\t\t\t\n\t\t## Predict\n\t\tdf_m2_pre.rename(columns = {0:\"score\"}, inplace = True)\n\t\tdf_m2_pre = pd.concat([df_m2_pre.reset_index(drop=True), \n\t\t\t\t\t\t\t   df_m2_sam[['Target', 'dt', 'code', 'amt', 'end']].reset_index(drop=True)], axis=1)\t\t\n\t\tdf_m2_pre['end_a1'] = df_m2_pre['end'] * df_m2_pre['Target']\t\t\t\n\t\tdf_m2_pre['end_a1_pred'] = df_m2_pre['end'] * df_m2_pre['score'] \n\t\tdf_m2_pre['model'] = 'M1' \n\t\tdf_m2_pre['case'] = case_flg\n\t\tdf_m2_pre['look_after'] = look_after\n\n\t\treturn df_m2_pre\n\n\tdf_m2_pre_c1 = f_modeling_1('c1')       \n\tdf_m2_pre_c2 = f_modeling_1('c2')\t\n\tdf_m2_pre_c1_tot = df_m2_pre_c1_tot.append(df_m2_pre_c1)\n\tdf_m2_pre_c2_tot = df_m2_pre_c2_tot.append(df_m2_pre_c2)",
      "metadata": {
        "trusted": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "text": "\n ===> look_after :  1\n[LightGBM] [Warning] Unknown parameter: n_leaves\n[LightGBM] [Warning] Unknown parameter: n_leaves\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002000 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29841\n[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 120\n[LightGBM] [Info] Start training from score 1.000430\n[LightGBM] [Warning] Unknown parameter: n_leaves\n[LightGBM] [Warning] Unknown parameter: n_leaves\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002000 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 29841\n[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 120\n[LightGBM] [Info] Start training from score 1.000730\n\n ===> look_after :  2\n[LightGBM] [Warning] Unknown parameter: n_leaves\n[LightGBM] [Warning] Unknown parameter: n_leaves\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000200 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 29841\n[LightGBM] [Info] Number of data points in the train set: 400, number of used features: 120\n[LightGBM] [Info] Start training from score 1.000858\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] Unknown parameter: n_leaves\n[LightGBM] [Warning] Unknown parameter: n_leaves\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000400 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 29841\n[LightGBM] [Info] Number of data points in the train set: 400, number of used features: 120\n[LightGBM] [Info] Start training from score 1.000716\n\n ===> look_after :  3\n[LightGBM] [Warning] Unknown parameter: n_leaves\n[LightGBM] [Warning] Unknown parameter: n_leaves\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000800 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 23028\n[LightGBM] [Info] Number of data points in the train set: 200, number of used features: 120\n[LightGBM] [Info] Start training from score 1.002942\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] Unknown parameter: n_leaves\n[LightGBM] [Warning] Unknown parameter: n_leaves\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000300 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 23227\n[LightGBM] [Info] Number of data points in the train set: 200, number of used features: 120\n[LightGBM] [Info] Start training from score 1.002424\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n ===> look_after :  4\n[LightGBM] [Warning] Unknown parameter: n_leaves\n[LightGBM] [Warning] Unknown parameter: n_leaves\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000100 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 11630\n[LightGBM] [Info] Number of data points in the train set: 100, number of used features: 120\n[LightGBM] [Info] Start training from score 1.000973\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] Unknown parameter: n_leaves\n[LightGBM] [Warning] Unknown parameter: n_leaves\n[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000200 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 11630\n[LightGBM] [Info] Number of data points in the train set: 100, number of used features: 120\n[LightGBM] [Info] Start training from score 1.003380\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n\n ===> look_after :  5\n[LightGBM] [Warning] Unknown parameter: n_leaves\n[LightGBM] [Warning] Unknown parameter: n_leaves\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000200 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6053\n[LightGBM] [Info] Number of data points in the train set: 50, number of used features: 120\n[LightGBM] [Info] Start training from score 0.999910\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] Unknown parameter: n_leaves\n[LightGBM] [Warning] Unknown parameter: n_leaves\n[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000200 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 5910\n[LightGBM] [Info] Number of data points in the train set: 50, number of used features: 120\n[LightGBM] [Info] Start training from score 1.001304\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
          "output_type": "stream"
        }
      ],
      "id": "d49f78cb"
    },
    {
      "cell_type": "markdown",
      "source": "# 2. 모델 후처리 및 제출\n\nStage 5에서 LGBM 모델에 적절한 데이터를 넣어 학습시켰고, 우리가 필요로 하는 Public 날짜와 Private 날짜의 주가를 예측했습니다.\n\n메인이 되는 모델링은 끝났고, 최종적으로 파일을 제출하기 위해 후처리 작업을 통해 데이터를 다듬도록 하겠습니다.\n\n",
      "metadata": {},
      "id": "61624494"
    },
    {
      "cell_type": "code",
      "source": "# 기준일 종가 추출\n\ndf_end_pub = df_price[(df_price['dt'] == pub_base_dt)]\ndf_end_pub = df_end_pub[df_end_pub['code'].isin(stock_list['code'])] \ndf_end_pri = df_price[(df_price['dt'] == pri_base_dt)]\ndf_end_pri = df_end_pri[df_end_pri['code'].isin(stock_list['code'])] ",
      "metadata": {
        "trusted": true
      },
      "execution_count": 4,
      "outputs": [],
      "id": "e72cbd59"
    },
    {
      "cell_type": "markdown",
      "source": "\nPublic 기준일, Private 기준일의 삼성전자 종가를 따로 빼어내, df_end_pub과 df_end_pri에 저장하였습니다.",
      "metadata": {},
      "id": "af669448"
    },
    {
      "cell_type": "code",
      "source": "# Public 후처리\ndf_submit_pub = df_m2_pre_c1_tot[['code', 'dt', 'end_a1_pred', 'look_after']]\ndf_submit_pub = pd.merge(stock_list[['code']], df_submit_pub, how='left', on=['code'])\ndf_submit_pub = pd.merge(df_submit_pub, df_end_pub[['code', 'dt', 'end']], how='left', on=['code'])\ndf_submit_pub['end_a1_pred'] = np.where(df_submit_pub['end_a1_pred'].isnull(), df_submit_pub['end'], df_submit_pub['end_a1_pred'])  # 거래정지\ndf_submit_pub['look_after']  = np.where(df_submit_pub['look_after'].isnull(), 1, df_submit_pub['look_after'])  \ndf_submit_pub = pd.pivot_table(df_submit_pub, index='look_after', columns='code', values='end_a1_pred')\ndf_submit_pub['Day'] = dl_predict_pub_day\ncols = df_submit_pub.columns.tolist()                  \ncols = cols[-1:] + cols[:-1]\ndf_submit_pub = df_submit_pub[cols] \t                \ndf_submit_pub = df_submit_pub.fillna(method='ffill')  \t",
      "metadata": {
        "trusted": true
      },
      "execution_count": 5,
      "outputs": [],
      "id": "5566334c"
    },
    {
      "cell_type": "markdown",
      "source": "**pd.pivot_table()** 함수가 조금 생소하실 수도 있을 것 같습니다.</br>\n**pivot_table()** 메소드는 피벗테이블을 생성하는 메소드로, 엑셀을 사용하신다면 한 번쯤 사용하셨을 수도 있을텐데요.\n\n\n**피벗(pivot)** 의 사전적 의미에 대해서 알아보면 피벗은 ‘회전 축’이라는 뜻을 가지고 있는데, 피벗 테이블도 축과 연관지어서 생각해볼 수 있습니다. \n\n우리가 표로 정리해서 보고자 하는 관점의 축을 잡고, 표로 만들어 주는 기능이 바로 **피벗 테이블**이라고 볼 수 있습니다.\n\n예를 들어, 우리가 특정 기간에 판매한 내역이 있다면 구매가 발생되는 요인을 파악하기 위해서 어떤 고객이 가장 많이 우리 매장에 방문했는지, 어떤 품목이 제일 잘 나갔는지 등등 다양한 관점에서 분석을 해보고 싶을 때가 있습니다. \n\n그렇게 다양한 관점에서 데이터를 확인해볼 수 있는 게 바로 피벗테이블입니다.\n\n피벗테이블은 보고 싶은 기준을 바로바로 변경해서 볼 수 있게되어 복잡하게 수식을 쓰거나 기준이 달라질 때마다 새로 작성을 할 필요가 없습니다.\n",
      "metadata": {},
      "id": "6a84a189"
    },
    {
      "cell_type": "code",
      "source": "## Private 후처리\ndf_submit_pri = df_m2_pre_c2_tot[['code', 'dt', 'end_a1_pred', 'look_after']]\ndf_submit_pri = pd.merge(stock_list[['code']], df_submit_pri, how='left', on=['code'])\ndf_submit_pri = pd.merge(df_submit_pri, df_end_pri[['code', 'dt', 'end']], how='left', on=['code'])\ndf_submit_pri['end_a1_pred'] = np.where(df_submit_pri['end_a1_pred'].isnull() & (df_submit_pri['code'] == '017670'), df_submit_pri['end']/5, # 액면분할 : sk텔레콤 5대 1\n                               np.where(df_submit_pri['end_a1_pred'].isnull() & df_submit_pri['end'].notnull(), df_submit_pri['end'],        # 거래정지\n                               np.where(df_submit_pri['end'].isnull(), 0, df_submit_pri['end_a1_pred'])))                                    # 상장폐지\ndf_submit_pri['look_after']  = np.where(df_submit_pri['look_after'].isnull(), 1, df_submit_pri['look_after'])  \ndf_submit_pri = pd.pivot_table(df_submit_pri, index='look_after', columns='code', values='end_a1_pred')\ndf_submit_pri['Day'] = dl_predict_pri_day\ncols = df_submit_pri.columns.tolist()                  \ncols = cols[-1:] + cols[:-1]\ndf_submit_pri = df_submit_pri[cols] \t                \ndf_submit_pri = df_submit_pri.fillna(method='ffill') \n\n## Public, Private 결합\ndf_submit = df_submit_pub.append(df_submit_pri)\ndf_submit = df_submit.reset_index(drop=True) \n\n## Submission\ntoday = datetime.datetime.today().strftime('%Y%m%d')\nstr_file = './submission_' + str(today) + '.csv'\ndf_submit.to_csv(str_file, index=False)  ",
      "metadata": {
        "trusted": true
      },
      "execution_count": 6,
      "outputs": [],
      "id": "ae5616f1"
    },
    {
      "cell_type": "markdown",
      "source": "\nsubmission.csv 파일은 다음과 같은 형식으로 구성되어 있습니다.\n\n<img src = \"https://cherry-orbit-69a.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fb1f8ee9a-1cfc-4df2-90c1-3ed651a3ad97%2FUntitled.png?id=8302014c-94f0-48d6-91f8-4f7b4badf090&table=block&spaceId=9b3f14ce-6c75-4c95-8989-493ed6e93a8a&width=700&userId=&cache=v2\">\n\n\n현재와 달라진 주식 종목 상황을 맞춰주고, 위의 형식을 맞춰주기 위해 코드를 적용했습니다.\n\n우리는 삼성전자(005930) 종목만 모델링을 진행했기 때문에, 저장한 파일에는 다음과 같은 형식으로 저장되어 있을 것입니다.\n\n<img src = \"https://cherry-orbit-69a.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F7c7f8a02-02f5-4f12-a430-c47bf427f665%2FUntitled.png?id=12b6d9a2-9969-40d2-bb3b-db6f4f91d17f&table=block&spaceId=9b3f14ce-6c75-4c95-8989-493ed6e93a8a&width=420&userId=&cache=v2\">\n\n\n\n\n데이커 여러분이 대회를 참여하게 된다면, 이제 이 파일을 대회의 **“제출”** 탭에 업로드하면 제출까지의 모든 과정이 마무리되게 됩니다.\n\n제출 파일을 업로드하면, 파일 검수 및 스코어 계산까지 약간의 시간이 소요되고 리더보드에서 여러분의 점수를 확인할 수 있을거에요!\n\n\n# 3. 마무리\n\n\n축하드립니다. 🎉</br>\n여러분은 이제 삼성전자의 주식을 예측할 수 있는 사람이 되었습니다. \n\n모든 스테이지를 저희 팀과 함께해주셔서 감사합니다! \n\n\n이 경험을 기반으로 다양한 주식 데이터를 활용해 주가의 향방을 예측할 수 있는 데이커가 되셨으면 좋겠습니다!\n\n이상으로 6단계에 걸친 **'주식 종가 예측 경진대회'** 의 PBL 학습을 완료하겠습니다!\n\n\n🐨 코알라팀 🐨\n\n",
      "metadata": {},
      "id": "8481c6cf"
    }
  ]
}